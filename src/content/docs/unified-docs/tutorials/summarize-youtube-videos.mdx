---
title: Summarize YouTube videos
description: Learn how to build a conversational application that allows users to summarize YouTube videos and chat about their contents using natural language across JavaScript, Go, and Python.
---

import LanguageSelector from '../../../../components/LanguageSelector.astro';
import LanguageContent from '../../../../components/LanguageContent.astro';
import CopyMarkdownButton from '../../../../components/CopyMarkdownButton.astro';

<div style="display: flex; justify-content: space-between; align-items: center; gap: 1rem; margin: 1rem 0 1rem 0;">
  <LanguageSelector />
  <CopyMarkdownButton />
</div>

This tutorial demonstrates how to build a conversational application that allows users to summarize YouTube videos and chat about their contents using natural language.

## What you'll build

By the end of this tutorial, you'll have a command-line application that:
- Processes YouTube video URLs
- Generates summaries or transcriptions of video content
- Allows custom prompts for different types of analysis

## Prerequisites

<LanguageContent lang="js">
- [Node.js v20+](https://nodejs.org/en/download)
- [npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)
</LanguageContent>

<LanguageContent lang="go">
- [Go 1.24+](https://go.dev/doc/install)
</LanguageContent>

<LanguageContent lang="python">
- [Python 3.10+](https://www.python.org/downloads/)
</LanguageContent>

## Step 1: Set up your project

<LanguageContent lang="js">
Create a directory structure and initialize your TypeScript project:

```bash
mkdir -p summarize-youtube/src && \
cd summarize-youtube && \
touch src/index.ts
```

Initialize a new TypeScript project:

```bash
npm init -y
```

Install the required dependencies:

```bash
npm install genkit @genkit-ai/googleai
```

- `genkit` - Genkit core capabilities
- `@genkit-ai/googleai` - Access to Google AI Gemini models with multimodal support
</LanguageContent>

<LanguageContent lang="go">
Create a new Go project:

```bash
mkdir summarize-youtube && cd summarize-youtube
go mod init summarize-youtube
```

Install the required dependencies:

```bash
go get github.com/firebase/genkit/go
```

Create your main file:

```bash
touch main.go
```
</LanguageContent>

<LanguageContent lang="python">
Create a new Python project:

```bash
mkdir summarize-youtube && cd summarize-youtube
```

(Recommended) Create and activate a virtual environment:

```bash
python3 -m venv .
source bin/activate  # for bash
```

Install the required dependencies:

```bash
pip install genkit genkit-plugin-google-genai
```

Create your main file:

```bash
touch main.py
```
</LanguageContent>

## Step 2: Configure your API key

To use the Gemini API, you'll need an API key. If you don't have one, [create a key](https://makersuite.google.com/app/apikey) in Google AI Studio.

Set the `GEMINI_API_KEY` environment variable:

```bash
export GEMINI_API_KEY=<your API key>
```

:::note
This tutorial uses Gemini's multimodal capabilities to process video content. Other providers may have different multimodal support. See [AI providers](/unified-docs/plugins/overview) for more options.
:::

## Step 3: Import dependencies and configure Genkit

<LanguageContent lang="js">
In your `src/index.ts` file, add the following imports and configuration:

```typescript
import { googleAI } from '@genkit-ai/googleai';
import { genkit } from 'genkit';

const ai = genkit({
  plugins: [googleAI()],
  model: googleAI.model('gemini-2.5-flash'),
});
```
</LanguageContent>

<LanguageContent lang="go">
In your `main.go` file, add the following imports and configuration:

```go
package main

import (
    "context"
    "fmt"
    "log"
    "os"

    "github.com/firebase/genkit/go/ai"
    "github.com/firebase/genkit/go/genkit"
    "github.com/firebase/genkit/go/plugins/googlegenai"
)

func main() {
    ctx := context.Background()

    // Initialize Genkit
    g, err := genkit.Init(ctx,
        genkit.WithPlugins(&googlegenai.GoogleAI{}),
        genkit.WithDefaultModel("googleai/gemini-2.5-flash"),
    )
    if err != nil {
        log.Fatalf("could not initialize Genkit: %v", err)
    }
    
    // Implementation continues...
}
```
</LanguageContent>

<LanguageContent lang="python">
In your `main.py` file, add the following imports and configuration:

```python
import sys
from genkit.ai import Genkit
from genkit.plugins.google_genai import GoogleAI

# Initialize Genkit
ai = Genkit(
    plugins=[GoogleAI()],
    model='googleai/gemini-2.5-flash',
)
```
</LanguageContent>

## Step 4: Process video URLs and generate responses

<LanguageContent lang="js">
Add the main function with video processing logic:

```typescript
(async () => {
  try {
    // Get command line arguments
    const videoURL = process.argv[2];
    if (!videoURL) {
      console.error('Please provide a video URL as a command line argument.');
      process.exit(1);
    }

    // Set up the prompt
    const prompt = process.argv[3] || 'Please summarize the following video:';

    // Process video with multimodal prompt
    const { text } = await ai.generate({
      prompt: [
        { text: prompt },
        { media: { url: videoURL, contentType: 'video/mp4' } }
      ],
    });

    console.log(text);
  } catch (error) {
    console.error('Error processing video:', error);
  }
})();
```
</LanguageContent>

<LanguageContent lang="go">
Continue implementing the main function:

```go
func main() {
    // ... (previous initialization code)

    // Get command line arguments
    if len(os.Args) < 2 {
        log.Fatal("Please provide a video URL as a command line argument.")
    }
    videoURL := os.Args[1]

    // Set up the prompt
    prompt := "Please summarize the following video:"
    if len(os.Args) > 2 {
        prompt = os.Args[2]
    }

    // Process video with multimodal prompt
    resp, err := ai.Generate(ctx, g,
        ai.WithPrompt(ai.NewUserMessage(
            ai.NewTextPart(prompt),
            ai.NewMediaPart(videoURL, "video/mp4"),
        )),
    )
    if err != nil {
        log.Fatalf("Error processing video: %v", err)
    }

    fmt.Println(resp.Text())
}
```
</LanguageContent>

<LanguageContent lang="python">
Add the main implementation:

```python
async def main():
    # Get command line arguments
    if len(sys.argv) < 2:
        print("Please provide a video URL as a command line argument.")
        sys.exit(1)
    
    video_url = sys.argv[1]
    
    try:
        # Set up the prompt
        prompt = sys.argv[2] if len(sys.argv) > 2 else "Please summarize the following video:"
        
        # Process video with multimodal prompt
        response = await ai.generate(
            prompt=[
                {"text": prompt},
                {"media": {"url": video_url, "contentType": "video/mp4"}}
            ]
        )
        
        print(response.text)
        
    except Exception as error:
        print(f"Error processing video: {error}")

# Run the application
ai.run_main(main())
```
</LanguageContent>

## Step 5: Run your application

<LanguageContent lang="js">
Run your application with a YouTube video URL:

```bash
npx tsx src/index.ts "https://www.youtube.com/watch?v=YUgXJkNqH9Q"
```

You can also provide a custom prompt:

```bash
npx tsx src/index.ts "https://www.youtube.com/watch?v=YUgXJkNqH9Q" "Transcribe this video"
```

:::note
If you get an error message saying "no matches found", you might need to wrap the video URL in quotes.
:::
</LanguageContent>

<LanguageContent lang="go">
Run your application with a YouTube video URL:

```bash
go run main.go "https://www.youtube.com/watch?v=YUgXJkNqH9Q"
```

You can also provide a custom prompt:

```bash
go run main.go "https://www.youtube.com/watch?v=YUgXJkNqH9Q" "Transcribe this video"
```
</LanguageContent>

<LanguageContent lang="python">
Run your application with a YouTube video URL:

```bash
python main.py "https://www.youtube.com/watch?v=YUgXJkNqH9Q"
```

You can also provide a custom prompt:

```bash
python main.py "https://www.youtube.com/watch?v=YUgXJkNqH9Q" "Transcribe this video"
```
</LanguageContent>

## Advanced usage examples

Here are some example prompts you can try:

### Summarization
```bash
# Basic summary
"Summarize the key points of this video"

# Detailed summary
"Provide a detailed summary with timestamps of major topics discussed"

# Executive summary
"Create a brief executive summary suitable for a business audience"
```

### Content analysis
```bash
# Extract action items
"List all action items and recommendations mentioned in this video"

# Identify speakers
"Identify the main speakers and their key contributions to the discussion"

# Technical analysis
"Extract all technical concepts and explain them in simple terms"
```

### Transcription
```bash
# Full transcription
"Transcribe this video word-for-word"

# Clean transcription
"Transcribe this video, removing filler words and cleaning up the text"
```

## What you learned

In this tutorial, you built a YouTube video summarization application that demonstrates:

- **Multimodal AI**: Processing video content with text prompts
- **Flexible prompting**: Using custom prompts for different analysis types
- **Command-line tools**: Building practical utilities with Genkit
- **Media handling**: Working with video URLs and content types

## Next steps

- Learn about [generating content](/unified-docs/generating-content) for more multimodal capabilities
- Explore [creating flows](/unified-docs/creating-flows) to build more complex video processing pipelines
- Try [different AI providers](/unified-docs/plugins/overview) that support multimodal inputs
- Build a web interface using [framework integrations](/unified-docs/frameworks/express)
- Combine with [RAG](/unified-docs/rag) to create a knowledge base from video content
