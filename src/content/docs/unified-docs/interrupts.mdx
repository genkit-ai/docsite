---
title: Pause generation using interrupts
description: Learn how to use interrupts in Genkit to pause and resume LLM generation, enabling human-in-the-loop interactions, asynchronous processing, and controlled task completion across JavaScript and Python.
---

import LanguageSelector from '../../../components/LanguageSelector.astro';
import LanguageContent from '../../../components/LanguageContent.astro';

<LanguageSelector />

:::caution[Beta]
This feature of Genkit is in **Beta,** which means it is not yet part of Genkit's stable API. APIs of beta features may change in minor version releases.
:::

_Interrupts_ are a special kind of [tool](/unified-docs/tool-calling) that can pause the
LLM generation-and-tool-calling loop to return control back to you. When
you're ready, you can then _resume_ generation by sending _replies_ that the LLM
processes for further generation.

The most common uses for interrupts fall into a few categories:

- **Human-in-the-Loop:** Enabling the user of an interactive AI
  to clarify needed information or confirm the LLM's action
  before it is completed, providing a measure of safety and confidence.
- **Async Processing:** Starting an asynchronous task that can only be
  completed out-of-band, such as sending an approval notification to
  a human reviewer or kicking off a long-running background process.
- **Exit from an Autonomous Task:** Providing the model a way
  to mark a task as complete, in a workflow that might iterate through
  a long series of tool calls.

## Availability

<LanguageContent lang="js">
Interrupts are fully supported in JavaScript with comprehensive APIs for defining, using, and responding to interrupts.
</LanguageContent>

<LanguageContent lang="go">
Interrupts are not currently available in Go. Use alternative patterns like conditional tool execution or external coordination mechanisms.
</LanguageContent>

<LanguageContent lang="python">
Interrupts are supported in Python with similar functionality to JavaScript, though with some API differences.
</LanguageContent>

## Before you begin

All of the examples documented here assume that you have already set up a
project with Genkit dependencies installed. If you want to run the code
examples on this page, first complete the steps in the Getting started guide for your language.

Before diving too deeply, you should also be familiar with the following
concepts:

- [Generating content](/unified-docs/generating-content) with AI models
- Genkit's system for [defining input and output schemas](/unified-docs/creating-flows)
- General methods of [tool calling](/unified-docs/tool-calling)

## Overview of interrupts

At a high level, this is what an interrupt looks like when
interacting with an LLM:

1. The calling application prompts the LLM with a request. The prompt includes
   a list of tools, including at least one for an interrupt that the LLM
   can use to generate a response.
2. The LLM generates either a complete response or a tool call request
   in a specific format. To the LLM, an interrupt call looks like any
   other tool call.
3. If the LLM calls an interrupt tool,
   the Genkit library automatically pauses generation rather than immediately
   passing responses back to the model for additional processing.
4. The developer checks whether an interrupt call is made, and performs whatever
   task is needed to collect the information needed for the interrupt response.
5. The developer resumes generation by passing an interrupt response to the
   model. This action triggers a return to Step 2.

## Define manual-response interrupts

The most common kind of interrupt allows the LLM to request clarification from
the user, for example by asking a multiple-choice question.

<LanguageContent lang="js">
Use the Genkit instance's `defineInterrupt()` method:

    ```ts
    import { genkit, z } from 'genkit';
    import { googleAI } from '@genkit-ai/googleai';

    const ai = genkit({
      plugins: [googleAI()],
      model: googleAI.model('gemini-2.5-flash'),
    });

    const askQuestion = ai.defineInterrupt({
      name: 'askQuestion',
      description: 'use this to ask the user a clarifying question',
      inputSchema: z.object({
        choices: z.array(z.string()).describe('the choices to display to the user'),
        allowOther: z.boolean().optional().describe('when true, allow write-ins'),
      }),
      outputSchema: z.string(),
    });
    ```

    Note that the `outputSchema` of an interrupt corresponds to the response data
    you will provide as opposed to something that will be automatically populated
    by a tool function.
</LanguageContent>

<LanguageContent lang="go">
Interrupts are not currently available in Go. Consider using alternative patterns:

    ```go
    // Alternative: Use conditional tool execution
    func conditionalTool(ctx context.Context, input ToolInput) (ToolOutput, error) {
        // Check conditions and return early if user confirmation needed
        if needsConfirmation(input) {
            return ToolOutput{
                Status: "NEEDS_CONFIRMATION",
                Message: "Please confirm this action",
            }, nil
        }
        
        // Proceed with normal execution
        return executeAction(input)
    }
    ```
</LanguageContent>

<LanguageContent lang="python">
Use the Genkit instance's `tool()` decorator:

    ```python
    from pydantic import BaseModel, Field

    class Questions(BaseModel):
        choices: list[str] = Field(description='the choices to display to the user')
        allow_other: bool = Field(description='when true, allow write-ins')

    @ai.tool()
    def ask_question(input: Questions, ctx) -> str:
        """Use this to ask the user a clarifying question"""
        ctx.interrupt()
    ```

    Note that the return type annotation of an interrupt corresponds to the response data
    you will provide as opposed to something that will be automatically populated
    by a tool function.
</LanguageContent>

## Use interrupts

Interrupts are passed into the `tools` array when generating content, just like
other types of tools. You can pass both normal tools and interrupts to the
same `generate` call:

<LanguageContent lang="js">
### Generate

    ```ts
    const response = await ai.generate({
      prompt: "Ask me a movie trivia question.",
      tools: [askQuestion],
    });
    ```

    ### definePrompt

    ```ts
    const triviaPrompt = ai.definePrompt({
      name: "triviaPrompt",
      tools: [askQuestion],
      input: {
        schema: z.object({ subject: z.string() }),
      },
      prompt: "Ask me a trivia question about {{subject}}.",
    });

    const response = await triviaPrompt({ subject: "computer history" });
    ```

    ### Prompt file

    ```dotprompt
    ---
    tools: [askQuestion]
    input:
      schema:
        partyType: string
    ---

    {{role "system"}}
    Use the askQuestion tool if you need to clarify something.

    {{role "user"}}
    Help me plan a {{partyType}} party next week.
    ```

    Then you can execute the prompt in your code as follows:

    ```ts
    // assuming prompt file is named partyPlanner.prompt
    const partyPlanner = ai.prompt("partyPlanner");

    const response = await partyPlanner({ partyType: "birthday" });
    ```

    ### Chat

    ```ts
    const chat = ai.chat({
      system: "Use the askQuestion tool if you need to clarify something.",
      tools: [askQuestion],
    });

    const response = await chat.send("make a plan for my birthday party");
    ```
</LanguageContent>

<LanguageContent lang="go">
Interrupts are not available in Go. Use alternative patterns like conditional tool execution or external coordination mechanisms.
</LanguageContent>

<LanguageContent lang="python">
```python
    interrupted_response = await ai.generate(
        prompt='Ask me a movie trivia question.',
        tools=['ask_question'],
    )
    ```
</LanguageContent>

Genkit immediately returns a response on receipt of an interrupt tool call.

## Respond to interrupts

If you've passed one or more interrupts to your generate call, you
need to check the response for interrupts so that you can handle them:

<LanguageContent lang="js">
```ts
    // you can check the 'finishReason' of the response
    response.finishReason === 'interrupted';
    // or you can check to see if any interrupt requests are on the response
    response.interrupts.length > 0;
    ```

    Responding to an interrupt is done using the `resume` option on a subsequent
    `generate` call, making sure to pass in the existing history. Each tool has
    a `.respond()` method on it to help construct the response.

    Once resumed, the model re-enters the generation loop, including tool
    execution, until either it completes or another interrupt is triggered:

    ```ts
    let response = await ai.generate({
      tools: [askQuestion],
      system: 'ask clarifying questions until you have a complete solution',
      prompt: 'help me plan a backyard BBQ',
    });

    while (response.interrupts.length) {
      const answers = [];
      // multiple interrupts can be called at once, so we handle them all
      for (const question of response.interrupts) {
        answers.push(
          // use the `respond` method on our tool to populate answers
          askQuestion.respond(
            question,
            // send the tool request input to the user to respond
            await askUser(question.toolRequest.input),
          ),
        );
      }

      response = await ai.generate({
        tools: [askQuestion],
        messages: response.messages,
        resume: {
          respond: answers,
        },
      });
    }

    // no more interrupts, we can see the final response
    console.log(response.text);
    ```
</LanguageContent>

<LanguageContent lang="go">
Not applicable - interrupts are not available in Go.
</LanguageContent>

<LanguageContent lang="python">
```python
    # You can check the 'finish_reason' attribute of the response
    if interrupted_response.finish_reason == 'interrupted':
        print("Generation interrupted.")

    # Or you can check if any interrupt requests are on the response
    if interrupted_response.interrupts and len(interrupted_response.interrupts) > 0:
        print(f"Interrupts found: {len(interrupted_response.interrupts)}")
    ```

    Responding to an interrupt is done using the `tool_responses` option on a subsequent
    `generate` call, making sure to pass in the existing history. There's a `tool_response`
    helper function to help you construct the response.

    Once resumed, the model re-enters the generation loop, including tool
    execution, until either it completes or another interrupt is triggered:

    ```python
    from genkit.ai import tool_response

    response = await ai.generate(
        messages=interrupted_response.messages,
        tool_responses=[tool_response(interrupted_response.interrupts[0], 'b')],
        tools=['ask_question'],
    )
    ```
</LanguageContent>

## Tools with restartable interrupts

Another common pattern for interrupts is the need to _confirm_ an action that
the LLM suggests before actually performing it. For example, a payments app
might want the user to confirm certain kinds of transfers.

<LanguageContent lang="js">
For this use case, you can use the standard `defineTool` method to add custom
    logic around when to trigger an interrupt, and what to do when an interrupt is
    _restarted_ with additional metadata.

    ### Define a restartable tool

    Every tool has access to two special helpers in the second argument of its
    implementation definition:

    - `interrupt`: when called, this method throws a special kind of exception that
      is caught to pause the generation loop. You can provide additional metadata
      as an object.
    - `resumed`: when a request from an interrupted generation is restarted using
      the `{resume: {restart: ...}}` option (see below), this helper contains the
      metadata provided when restarting.

    If you were building a payments app, for example, you might want to confirm with
    the user before making a transfer exceeding a certain amount:

    ```ts
    const transferMoney = ai.defineTool({
      name: 'transferMoney',
      description: 'Transfers money between accounts.',
      inputSchema: z.object({
        toAccountId: z.string().describe('the account id of the transfer destination'),
        amount: z.number().describe('the amount in integer cents (100 = $1.00)'),
      }),
      outputSchema: z.object({
        status: z.string().describe('the outcome of the transfer'),
        message: z.string().optional(),
      })
    }, async (input, {context, interrupt, resumed}) => {
      // if the user rejected the transaction
      if (resumed?.status === "REJECTED") {
        return {status: 'REJECTED', message: 'The user rejected the transaction.'};
      }
      // trigger an interrupt to confirm if amount > $100
      if (resumed?.status !== "APPROVED" && input.amount > 10000) {
        interrupt({
          message: "Please confirm sending an amount > $100.",
        });
      }
      // complete the transaction if not interrupted
      return doTransfer(input);
    });
    ```

    In this example, on first execution (when `resumed` is undefined), the tool
    checks to see if the amount exceeds $100, and triggers an interrupt if so. On
    second execution, it looks for a status in the new metadata provided and
    performs the transfer or returns a rejection response, depending on whether it
    is approved or rejected.

    ### Restart tools after interruption

    Interrupt tools give you full control over:

    1. When an initial tool request should trigger an interrupt.
    2. When and whether to resume the generation loop.
    3. What additional information to provide to the tool when resuming.

    In the example shown in the previous section, the application might ask the user
    to confirm the interrupted request to make sure the transfer amount is okay:

    ```ts
    let response = await ai.generate({
      tools: [transferMoney],
      prompt: "Transfer $1000 to account ABC123",
    });

    while (response.interrupts.length) {
      const confirmations = [];
      // multiple interrupts can be called at once, so we handle them all
      for (const interrupt of response.interrupts) {
        confirmations.push(
          // use the 'restart' method on our tool to provide `resumed` metadata
          transferMoney.restart(
            interrupt,
            // send the tool request input to the user to respond. assume that this
            // returns `{status: "APPROVED"}` or `{status: "REJECTED"}`
            await requestConfirmation(interrupt.toolRequest.input)
          )
        );
      }

      response = await ai.generate({
        tools: [transferMoney],
        messages: response.messages,
        resume: {
          restart: confirmations,
        }
      })
    }

    // no more interrupts, we can see the final response
    console.log(response.text);
    ```
</LanguageContent>

<LanguageContent lang="go">
Not applicable - interrupts are not available in Go. Consider implementing confirmation logic within your tools:

    ```go
    func transferMoney(ctx context.Context, input TransferInput) (TransferOutput, error) {
        // Implement confirmation logic within the tool
        if input.Amount > 10000 && !input.Confirmed {
            return TransferOutput{
                Status: "NEEDS_CONFIRMATION",
                Message: "Please confirm transfer amount > $100",
                RequiresConfirmation: true,
            }, nil
        }
        
        // Proceed with transfer if confirmed or amount is small
        return executeTransfer(input)
    }
    ```
</LanguageContent>

<LanguageContent lang="python">
Similar patterns are available in Python, though the specific APIs may differ. Consult the Python documentation for the most current implementation details.
</LanguageContent>

## Best practices

### When to use interrupts

<LanguageContent lang="js">
- **User confirmation**: For actions that have significant consequences (payments, deletions, etc.)
    - **Missing information**: When the LLM needs clarification to proceed
    - **Async operations**: For long-running tasks that need to complete out-of-band
    - **Safety checks**: To add human oversight to autonomous AI workflows
</LanguageContent>

<LanguageContent lang="go">
Since interrupts are not available, consider these alternatives:
    - **Conditional tools**: Return status codes that indicate when confirmation is needed
    - **Multi-step flows**: Break complex operations into smaller, confirmable steps
    - **External coordination**: Use external systems to manage approval workflows
</LanguageContent>

<LanguageContent lang="python">
- **User confirmation**: For actions that have significant consequences
    - **Missing information**: When the LLM needs clarification to proceed
    - **Async operations**: For long-running tasks that need to complete out-of-band
    - **Safety checks**: To add human oversight to autonomous AI workflows
</LanguageContent>

### Error handling

<LanguageContent lang="js">
Always handle the case where interrupts might not be responded to:

    ```ts
    let response = await ai.generate({
      tools: [askQuestion],
      prompt: 'help me plan a party',
    });

    let maxRetries = 3;
    let retryCount = 0;

    while (response.interrupts.length && retryCount < maxRetries) {
      try {
        // Handle interrupts...
        response = await ai.generate({
          tools: [askQuestion],
          messages: response.messages,
          resume: { respond: answers },
        });
        retryCount++;
      } catch (error) {
        console.error('Error handling interrupt:', error);
        break;
      }
    }
    ```
</LanguageContent>

<LanguageContent lang="go">
Implement proper error handling in your conditional tools:

    ```go
    func handleConditionalTool(ctx context.Context, input ToolInput) (ToolOutput, error) {
        if needsConfirmation(input) {
            return ToolOutput{
                Status: "NEEDS_CONFIRMATION",
                Message: "Please confirm this action",
            }, nil
        }
        
        result, err := executeAction(input)
        if err != nil {
            return ToolOutput{}, fmt.Errorf("action failed: %w", err)
        }
        
        return result, nil
    }
    ```
</LanguageContent>

<LanguageContent lang="python">
Always handle the case where interrupts might not be responded to:

    ```python
    try:
        response = await ai.generate(
            messages=interrupted_response.messages,
            tool_responses=[tool_response(interrupted_response.interrupts[0], user_input)],
            tools=['ask_question'],
        )
    except Exception as e:
        print(f"Error handling interrupt: {e}")
        # Handle error appropriately
    ```
</LanguageContent>

## Next steps

- Learn about [tool calling](/unified-docs/tool-calling) to understand the foundation that interrupts build upon
- Explore [creating flows](/unified-docs/creating-flows) to build complex AI workflows that incorporate interrupts
- See [developer tools](/unified-docs/developer-tools) for testing and debugging interrupt-enabled applications
- Check out [generating content](/unified-docs/generating-content) for understanding the generation loop that interrupts can pause
