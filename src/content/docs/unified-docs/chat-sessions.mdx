---
title: Creating persistent chat sessions
description: Learn how to create persistent chat sessions in Genkit, including session basics, stateful sessions, multi-thread sessions, and session persistence across different languages.
---

import { Tabs, TabItem } from '@astrojs/starlight/components';

:::caution[Beta]
This feature of Genkit is in **Beta,** which means it is not yet part of Genkit's stable API. APIs of beta features may change in minor version releases.
:::

Many of your users will have interacted with large language models for the first
time through chatbots. Although LLMs are capable of much more than simulating
conversations, it remains a familiar and useful style of interaction. Even when
your users will not be interacting directly with the model in this way, the
conversational style of prompting is a powerful way to influence the output
generated by an AI model.

Genkit provides different approaches for building chat-based LLM applications depending on your language choice.

## Availability and Approach

<Tabs syncKey="language">
  <TabItem label="JavaScript" icon="seti:javascript">
    JavaScript provides comprehensive chat session APIs with built-in persistence, state management, and multi-thread support. Chat sessions are available through the `genkit/beta` package.

    Features include:
    - Automatic message history management
    - Stateful sessions with custom state objects
    - Multi-thread sessions within a single session
    - Pluggable session storage backends
    - Integration with tools and context
  </TabItem>
  <TabItem label="Go" icon="seti:go">
    Go doesn't have built-in chat session APIs. You need to implement chat functionality manually by:
    - Managing message history in your application
    - Implementing conversation state persistence
    - Building your own session management system
    - Manually including conversation history in generation calls
  </TabItem>
  <TabItem label="Python" icon="seti:python">
    Python doesn't have built-in chat session APIs. You need to implement chat functionality manually by:
    - Managing message history in your application
    - Implementing conversation state persistence
    - Building your own session management system
    - Manually including conversation history in generation calls
  </TabItem>
</Tabs>

## Before you begin

Before reading this page, you should be familiar with the content covered on the
[Generating content](/unified-docs/generating-content) page.

If you want to run the code examples on this page, first complete the steps in
the Getting started guide for your language. All of the examples assume that you
have already installed Genkit as a dependency in your project.

## Chat session basics

<Tabs syncKey="language">
  <TabItem label="JavaScript" icon="seti:javascript">
    Here is a minimal, console-based, chatbot application:

    ```ts
    import { genkit } from 'genkit/beta';
    import { googleAI } from '@genkit-ai/googleai';

    import { createInterface } from 'node:readline/promises';

    const ai = genkit({
      plugins: [googleAI()],
      model: googleAI.model('gemini-2.5-flash'),
    });

    async function main() {
      const chat = ai.chat();
      console.log("You're chatting with Gemini. Ctrl-C to quit.\n");
      const readline = createInterface(process.stdin, process.stdout);
      while (true) {
        const userInput = await readline.question('> ');
        const { text } = await chat.send(userInput);
        console.log(text);
      }
    }

    main();
    ```

    A chat session with this program looks something like the following example:

    ```
    You're chatting with Gemini. Ctrl-C to quit.

    > hi
    Hi there! How can I help you today?

    > my name is pavel
    Nice to meet you, Pavel! What can I do for you today?

    > what's my name?
    Your name is Pavel! I remembered it from our previous interaction.

    Is there anything else I can help you with?
    ```

    As you can see from this brief interaction, when you send a message to a chat
    session, the model can make use of the session so far in its responses. This is
    possible because Genkit does a few things behind the scenes:

    - Retrieves the chat history, if any exists, from storage
    - Sends the request to the model, but automatically includes the chat history
    - Saves the model response into the chat history

    ### Model configuration

    The `chat()` method accepts most of the same configuration options as
    `generate()`. To pass configuration options to the model:

    ```ts
    const chat = ai.chat({
      model: googleAI.model('gemini-2.5-flash'),
      system: "You're a pirate first mate. Address the user as Captain and assist " + 'them however you can.',
      config: {
        temperature: 1.3,
      },
    });
    ```
  </TabItem>
  <TabItem label="Go" icon="seti:go">
    In Go, you need to manually manage conversation history. Here's an example implementation:

    ```go
    package main

    import (
        "bufio"
        "context"
        "fmt"
        "os"
        "strings"

        "github.com/firebase/genkit/go/ai"
        "github.com/firebase/genkit/go/genkit"
        "github.com/firebase/genkit/go/plugins/googleai"
    )

    type ChatMessage struct {
        Role    string
        Content string
    }

    type ChatSession struct {
        Messages []ChatMessage
        genkit   *genkit.Genkit
    }

    func NewChatSession(g *genkit.Genkit) *ChatSession {
        return &ChatSession{
            Messages: make([]ChatMessage, 0),
            genkit:   g,
        }
    }

    func (c *ChatSession) Send(ctx context.Context, userInput string) (string, error) {
        // Add user message to history
        c.Messages = append(c.Messages, ChatMessage{
            Role:    "user",
            Content: userInput,
        })

        // Build conversation history for the prompt
        var conversationHistory strings.Builder
        for _, msg := range c.Messages[:len(c.Messages)-1] { // Exclude the current message
            conversationHistory.WriteString(fmt.Sprintf("%s: %s\n", msg.Role, msg.Content))
        }

        // Generate response with conversation context
        prompt := fmt.Sprintf("Previous conversation:\n%s\nUser: %s\nAssistant:", 
            conversationHistory.String(), userInput)

        resp, err := genkit.Generate(ctx, c.genkit,
            ai.WithPrompt(prompt),
            ai.WithModelName("googleai/gemini-2.5-flash"),
        )
        if err != nil {
            return "", err
        }

        // Add assistant response to history
        assistantResponse := resp.Text()
        c.Messages = append(c.Messages, ChatMessage{
            Role:    "assistant",
            Content: assistantResponse,
        })

        return assistantResponse, nil
    }

    func main() {
        ctx := context.Background()
        g, err := genkit.Init(ctx, genkit.WithPlugins(&googleai.GoogleAI{}))
        if err != nil {
            panic(err)
        }

        chat := NewChatSession(g)
        fmt.Println("You're chatting with Gemini. Type 'quit' to exit.\n")

        scanner := bufio.NewScanner(os.Stdin)
        for {
            fmt.Print("> ")
            if !scanner.Scan() {
                break
            }
            
            userInput := strings.TrimSpace(scanner.Text())
            if userInput == "quit" {
                break
            }

            response, err := chat.Send(ctx, userInput)
            if err != nil {
                fmt.Printf("Error: %v\n", err)
                continue
            }

            fmt.Println(response)
        }
    }
    ```
  </TabItem>
  <TabItem label="Python" icon="seti:python">
    In Python, you need to manually manage conversation history. Here's an example implementation:

    ```python
    import asyncio
    from typing import List, Dict
    from genkit.ai import Genkit
    from genkit.plugins.google_genai import GoogleGenai, google_genai_name

    class ChatMessage:
        def __init__(self, role: str, content: str):
            self.role = role
            self.content = content

    class ChatSession:
        def __init__(self, ai: Genkit):
            self.messages: List[ChatMessage] = []
            self.ai = ai

        async def send(self, user_input: str) -> str:
            # Add user message to history
            self.messages.append(ChatMessage("user", user_input))

            # Build conversation history for the prompt
            conversation_history = ""
            for msg in self.messages[:-1]:  # Exclude the current message
                conversation_history += f"{msg.role}: {msg.content}\n"

            # Generate response with conversation context
            prompt = f"Previous conversation:\n{conversation_history}\nUser: {user_input}\nAssistant:"

            response = await self.ai.generate(
                prompt=prompt,
                model=google_genai_name('gemini-2.5-flash'),
            )

            # Add assistant response to history
            assistant_response = response.text
            self.messages.append(ChatMessage("assistant", assistant_response))

            return assistant_response

    async def main():
        ai = Genkit(
            plugins=[GoogleGenai()],
            model=google_genai_name('gemini-2.5-flash'),
        )

        chat = ChatSession(ai)
        print("You're chatting with Gemini. Type 'quit' to exit.\n")

        while True:
            user_input = input("> ").strip()
            if user_input.lower() == 'quit':
                break

            try:
                response = await chat.send(user_input)
                print(response)
            except Exception as e:
                print(f"Error: {e}")

    if __name__ == "__main__":
        asyncio.run(main())
    ```
  </TabItem>
</Tabs>

## Stateful chat sessions

<Tabs syncKey="language">
  <TabItem label="JavaScript" icon="seti:javascript">
    In addition to persisting a chat session's message history, you can also persist
    any arbitrary JavaScript object. Doing so can let you manage state in a more
    structured way than relying only on information in the message history.

    To include state in a session, you need to instantiate a session explicitly:

    ```ts
    interface MyState {
      userName: string;
    }

    const session = ai.createSession<MyState>({
      initialState: {
        userName: 'Pavel',
      },
    });
    ```

    You can then start a chat within the session:

    ```ts
    const chat = session.chat();
    ```

    To modify the session state based on how the chat unfolds, define
    [tools](/unified-docs/tool-calling) and include them with your requests:

    ```ts
    const changeUserName = ai.defineTool(
      {
        name: 'changeUserName',
        description: 'can be used to change user name',
        inputSchema: z.object({
          newUserName: z.string(),
        }),
      },
      async (input) => {
        await ai.currentSession<MyState>().updateState({
          userName: input.newUserName,
        });
        return `changed username to ${input.newUserName}`;
      },
    );
    ```

    ```ts
    const chat = session.chat({
      model: googleAI.model('gemini-2.5-flash'),
      tools: [changeUserName],
    });
    await chat.send('change user name to Kevin');
    ```
  </TabItem>
  <TabItem label="Go" icon="seti:go">
    In Go, you can implement stateful sessions by extending your chat session struct:

    ```go
    type UserState struct {
        UserName string
        // Add other state fields as needed
    }

    type StatefulChatSession struct {
        Messages []ChatMessage
        State    UserState
        genkit   *genkit.Genkit
    }

    func NewStatefulChatSession(g *genkit.Genkit, initialState UserState) *StatefulChatSession {
        return &StatefulChatSession{
            Messages: make([]ChatMessage, 0),
            State:    initialState,
            genkit:   g,
        }
    }

    func (c *StatefulChatSession) UpdateState(newState UserState) {
        c.State = newState
    }

    func (c *StatefulChatSession) Send(ctx context.Context, userInput string) (string, error) {
        // Include state information in the prompt
        stateInfo := fmt.Sprintf("Current user: %s", c.State.UserName)
        
        // Add user message to history
        c.Messages = append(c.Messages, ChatMessage{
            Role:    "user",
            Content: userInput,
        })

        // Build conversation history with state context
        var conversationHistory strings.Builder
        conversationHistory.WriteString(fmt.Sprintf("Context: %s\n", stateInfo))
        for _, msg := range c.Messages[:len(c.Messages)-1] {
            conversationHistory.WriteString(fmt.Sprintf("%s: %s\n", msg.Role, msg.Content))
        }

        prompt := fmt.Sprintf("%s\nUser: %s\nAssistant:", 
            conversationHistory.String(), userInput)

        resp, err := genkit.Generate(ctx, c.genkit,
            ai.WithPrompt(prompt),
            ai.WithModelName("googleai/gemini-2.5-flash"),
        )
        if err != nil {
            return "", err
        }

        assistantResponse := resp.Text()
        c.Messages = append(c.Messages, ChatMessage{
            Role:    "assistant",
            Content: assistantResponse,
        })

        return assistantResponse, nil
    }
    ```
  </TabItem>
  <TabItem label="Python" icon="seti:python">
    In Python, you can implement stateful sessions by extending your chat session class:

    ```python
    from dataclasses import dataclass
    from typing import Any, Dict

    @dataclass
    class UserState:
        user_name: str
        # Add other state fields as needed

    class StatefulChatSession:
        def __init__(self, ai: Genkit, initial_state: UserState):
            self.messages: List[ChatMessage] = []
            self.state = initial_state
            self.ai = ai

        def update_state(self, new_state: UserState):
            self.state = new_state

        async def send(self, user_input: str) -> str:
            # Include state information in the prompt
            state_info = f"Current user: {self.state.user_name}"
            
            # Add user message to history
            self.messages.append(ChatMessage("user", user_input))

            # Build conversation history with state context
            conversation_history = f"Context: {state_info}\n"
            for msg in self.messages[:-1]:
                conversation_history += f"{msg.role}: {msg.content}\n"

            prompt = f"{conversation_history}\nUser: {user_input}\nAssistant:"

            response = await self.ai.generate(
                prompt=prompt,
                model=google_genai_name('gemini-2.5-flash'),
            )

            # Add assistant response to history
            assistant_response = response.text
            self.messages.append(ChatMessage("assistant", assistant_response))

            return assistant_response

    # Usage
    initial_state = UserState(user_name="Pavel")
    chat = StatefulChatSession(ai, initial_state)
    ```
  </TabItem>
</Tabs>

## Multi-thread sessions

<Tabs syncKey="language">
  <TabItem label="JavaScript" icon="seti:javascript">
    A single session can contain multiple chat threads. Each thread has its own
    message history, but they share a single session state.

    ```ts
    const lawyerChat = session.chat('lawyerThread', {
      system: 'talk like a lawyer',
    });
    const pirateChat = session.chat('pirateThread', {
      system: 'talk like a pirate',
    });
    ```
  </TabItem>
  <TabItem label="Go" icon="seti:go">
    In Go, you can implement multi-thread sessions by managing multiple message histories:

    ```go
    type MultiThreadSession struct {
        Threads map[string][]ChatMessage
        State   UserState
        genkit  *genkit.Genkit
    }

    func NewMultiThreadSession(g *genkit.Genkit, initialState UserState) *MultiThreadSession {
        return &MultiThreadSession{
            Threads: make(map[string][]ChatMessage),
            State:   initialState,
            genkit:  g,
        }
    }

    func (m *MultiThreadSession) SendToThread(ctx context.Context, threadID, userInput, systemPrompt string) (string, error) {
        // Initialize thread if it doesn't exist
        if _, exists := m.Threads[threadID]; !exists {
            m.Threads[threadID] = make([]ChatMessage, 0)
        }

        // Add user message to thread history
        m.Threads[threadID] = append(m.Threads[threadID], ChatMessage{
            Role:    "user",
            Content: userInput,
        })

        // Build conversation history for this thread
        var conversationHistory strings.Builder
        conversationHistory.WriteString(fmt.Sprintf("System: %s\n", systemPrompt))
        for _, msg := range m.Threads[threadID][:len(m.Threads[threadID])-1] {
            conversationHistory.WriteString(fmt.Sprintf("%s: %s\n", msg.Role, msg.Content))
        }

        prompt := fmt.Sprintf("%s\nUser: %s\nAssistant:", 
            conversationHistory.String(), userInput)

        resp, err := genkit.Generate(ctx, m.genkit,
            ai.WithPrompt(prompt),
            ai.WithModelName("googleai/gemini-2.5-flash"),
        )
        if err != nil {
            return "", err
        }

        assistantResponse := resp.Text()
        m.Threads[threadID] = append(m.Threads[threadID], ChatMessage{
            Role:    "assistant",
            Content: assistantResponse,
        })

        return assistantResponse, nil
    }

    // Usage
    session := NewMultiThreadSession(g, UserState{UserName: "Pavel"})
    lawyerResponse, _ := session.SendToThread(ctx, "lawyer", "Hello", "Talk like a lawyer")
    pirateResponse, _ := session.SendToThread(ctx, "pirate", "Hello", "Talk like a pirate")
    ```
  </TabItem>
  <TabItem label="Python" icon="seti:python">
    In Python, you can implement multi-thread sessions by managing multiple message histories:

    ```python
    class MultiThreadSession:
        def __init__(self, ai: Genkit, initial_state: UserState):
            self.threads: Dict[str, List[ChatMessage]] = {}
            self.state = initial_state
            self.ai = ai

        async def send_to_thread(self, thread_id: str, user_input: str, system_prompt: str) -> str:
            # Initialize thread if it doesn't exist
            if thread_id not in self.threads:
                self.threads[thread_id] = []

            # Add user message to thread history
            self.threads[thread_id].append(ChatMessage("user", user_input))

            # Build conversation history for this thread
            conversation_history = f"System: {system_prompt}\n"
            for msg in self.threads[thread_id][:-1]:
                conversation_history += f"{msg.role}: {msg.content}\n"

            prompt = f"{conversation_history}\nUser: {user_input}\nAssistant:"

            response = await self.ai.generate(
                prompt=prompt,
                model=google_genai_name('gemini-2.5-flash'),
            )

            # Add assistant response to thread history
            assistant_response = response.text
            self.threads[thread_id].append(ChatMessage("assistant", assistant_response))

            return assistant_response

    # Usage
    session = MultiThreadSession(ai, UserState(user_name="Pavel"))
    lawyer_response = await session.send_to_thread("lawyer", "Hello", "Talk like a lawyer")
    pirate_response = await session.send_to_thread("pirate", "Hello", "Talk like a pirate")
    ```
  </TabItem>
</Tabs>

## Session persistence

<Tabs syncKey="language">
  <TabItem label="JavaScript" icon="seti:javascript">
    When you initialize a new chat or session, it's configured by default to store
    the session in memory only. This is adequate when the session needs to persist
    only for the duration of a single invocation of your program. However, when integrating LLM chat into
    an application, you will usually deploy your content generation logic as
    stateless web API endpoints. For persistent chats to work under this setup, you
    will need to implement some kind of session storage that can persist state
    across invocations of your endpoints.

    To add persistence to a chat session, you need to implement Genkit's
    `SessionStore` interface. Here is an example implementation that saves session
    state to individual JSON files:

    ```ts
    class JsonSessionStore<S = any> implements SessionStore<S> {
      async get(sessionId: string): Promise<SessionData<S> | undefined> {
        try {
          const s = await readFile(`${sessionId}.json`, { encoding: 'utf8' });
          const data = JSON.parse(s);
          return data;
        } catch {
          return undefined;
        }
      }

      async save(sessionId: string, sessionData: SessionData<S>): Promise<void> {
        const s = JSON.stringify(sessionData);
        await writeFile(`${sessionId}.json`, s, { encoding: 'utf8' });
      }
    }
    ```

    This implementation is probably not adequate for practical deployments, but it
    illustrates that a session storage implementation only needs to accomplish two
    tasks:

    - Get a session object from storage using its session ID
    - Save a given session object, indexed by its session ID

    Once you've implemented the interface for your storage backend, pass an instance
    of your implementation to the session constructors:

    ```ts
    // To create a new session:
    const session = ai.createSession({
      store: new JsonSessionStore(),
    });

    // Save session.id so you can restore the session the next time the
    // user makes a request.
    ```

    ```ts
    // If the user has a session ID saved, load the session instead of creating
    // a new one:
    const session = await ai.loadSession(sessionId, {
      store: new JsonSessionStore(),
    });
    ```
  </TabItem>
  <TabItem label="Go" icon="seti:go">
    In Go, you need to implement your own persistence layer. Here's an example using JSON files:

    ```go
    import (
        "encoding/json"
        "fmt"
        "os"
    )

    type SessionData struct {
        ID       string         `json:"id"`
        Messages []ChatMessage  `json:"messages"`
        State    UserState      `json:"state"`
    }

    type SessionStore struct {
        basePath string
    }

    func NewSessionStore(basePath string) *SessionStore {
        return &SessionStore{basePath: basePath}
    }

    func (s *SessionStore) Save(sessionID string, data SessionData) error {
        filename := fmt.Sprintf("%s/%s.json", s.basePath, sessionID)
        
        jsonData, err := json.MarshalIndent(data, "", "  ")
        if err != nil {
            return err
        }
        
        return os.WriteFile(filename, jsonData, 0644)
    }

    func (s *SessionStore) Load(sessionID string) (*SessionData, error) {
        filename := fmt.Sprintf("%s/%s.json", s.basePath, sessionID)
        
        data, err := os.ReadFile(filename)
        if err != nil {
            return nil, err
        }
        
        var sessionData SessionData
        err = json.Unmarshal(data, &sessionData)
        if err != nil {
            return nil, err
        }
        
        return &sessionData, nil
    }

    // Usage
    store := NewSessionStore("./sessions")
    
    // Save session
    sessionData := SessionData{
        ID:       "user123",
        Messages: chat.Messages,
        State:    chat.State,
    }
    err := store.Save("user123", sessionData)
    
    // Load session
    loadedData, err := store.Load("user123")
    if err == nil {
        // Restore chat session from loaded data
        chat.Messages = loadedData.Messages
        chat.State = loadedData.State
    }
    ```
  </TabItem>
  <TabItem label="Python" icon="seti:python">
    In Python, you need to implement your own persistence layer. Here's an example using JSON files:

    ```python
    import json
    import os
    from typing import Optional
    from dataclasses import asdict, dataclass

    @dataclass
    class SessionData:
        id: str
        messages: List[Dict[str, str]]
        state: Dict[str, Any]

    class SessionStore:
        def __init__(self, base_path: str):
            self.base_path = base_path
            os.makedirs(base_path, exist_ok=True)

        async def save(self, session_id: str, data: SessionData) -> None:
            filename = os.path.join(self.base_path, f"{session_id}.json")
            
            with open(filename, 'w') as f:
                json.dump(asdict(data), f, indent=2)

        async def load(self, session_id: str) -> Optional[SessionData]:
            filename = os.path.join(self.base_path, f"{session_id}.json")
            
            try:
                with open(filename, 'r') as f:
                    data = json.load(f)
                    return SessionData(**data)
            except FileNotFoundError:
                return None

    # Usage
    store = SessionStore("./sessions")

    # Save session
    session_data = SessionData(
        id="user123",
        messages=[{"role": msg.role, "content": msg.content} for msg in chat.messages],
        state=asdict(chat.state)
    )
    await store.save("user123", session_data)

    # Load session
    loaded_data = await store.load("user123")
    if loaded_data:
        # Restore chat session from loaded data
        chat.messages = [ChatMessage(msg["role"], msg["content"]) for msg in loaded_data.messages]
        chat.state = UserState(**loaded_data.state)
    ```
  </TabItem>
</Tabs>

## Best practices

### Memory management

<Tabs syncKey="language">
  <TabItem label="JavaScript" icon="seti:javascript">
    - Use session storage for production deployments
    - Implement session cleanup for old or inactive sessions
    - Consider limiting conversation history length for very long chats
    - Use compression for large session data
  </TabItem>
  <TabItem label="Go" icon="seti:go">
    - Implement proper error handling for persistence operations
    - Use structured logging for session operations
    - Consider using a database instead of files for production
    - Implement session cleanup and garbage collection
  </TabItem>
  <TabItem label="Python" icon="seti:python">
    - Use async I/O for session persistence operations
    - Implement proper error handling and retries
    - Consider using a database for production deployments
    - Monitor memory usage for long conversations
  </TabItem>
</Tabs>

### Security considerations

<Tabs syncKey="language">
  <TabItem label="JavaScript" icon="seti:javascript">
    - Validate session IDs to prevent path traversal attacks
    - Encrypt sensitive session data at rest
    - Implement session expiration and cleanup
    - Use secure session ID generation
  </TabItem>
  <TabItem label="Go" icon="seti:go">
    - Validate all input data before storing
    - Use secure file permissions for session storage
    - Implement proper authentication for session access
    - Consider using encrypted storage backends
  </TabItem>
  <TabItem label="Python" icon="seti:python">
    - Validate session IDs and sanitize file paths
    - Use secure serialization methods
    - Implement proper access controls
    - Consider using encrypted storage solutions
  </TabItem>
</Tabs>

## Next steps

- Learn about [tool calling](/unified-docs/tool-calling) to add interactive capabilities to your chat sessions
- Explore [context](/unified-docs/context) to understand how to pass information through chat sessions
- See [developer tools](/unified-docs/developer-tools) for testing and debugging chat applications
- Check out [generating content](/unified-docs/generating-content) for understanding the underlying generation mechanics
