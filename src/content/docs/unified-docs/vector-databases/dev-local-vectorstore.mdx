---
title: Dev Local Vector Store
description: Learn how to use the Dev Local Vector Store for local development and testing across JavaScript, Go, and Python with Genkit.
---

import LanguageSelector from '../../../../components/LanguageSelector.astro';
import LanguageContent from '../../../../components/LanguageContent.astro';

<LanguageSelector />

The Dev Local Vector Store provides a simple, file-based vector database solution for local development and testing. It's designed to be lightweight and easy to set up, making it perfect for prototyping, testing, and development environments where you don't need the complexity of a full production vector database.

## Key Features

- **Zero setup**: No external dependencies or services required
- **File-based storage**: Stores vectors and metadata locally
- **Development focused**: Optimized for quick iteration and testing
- **Lightweight**: Minimal resource usage
- **Cross-platform**: Works on any system with file system access

:::caution
The Dev Local Vector Store is intended for development and testing only. For production applications, use a dedicated vector database like Pinecone, ChromaDB, or Cloud Firestore.
:::

## Installation and Setup

<LanguageContent lang="js">
JavaScript doesn't have a dedicated dev local vector store plugin, but you can create a simple in-memory or file-based solution for development:

    ```bash
    npm install genkit
    ```

    Create a simple local vector store:

    ```ts
    import { genkit } from 'genkit';
    import { googleAI } from '@genkit-ai/googleai';
    import fs from 'fs/promises';
    import path from 'path';

    const ai = genkit({
      plugins: [googleAI()],
    });

    // Simple local vector store implementation
    class DevLocalVectorStore {
      private storePath: string;
      private embedder: any;

      constructor(storePath: string, embedder: any) {
        this.storePath = storePath;
        this.embedder = embedder;
      }

      async index(documents: string[]) {
        const embeddings = await Promise.all(
          documents.map(async (doc) => {
            const result = await ai.embed({
              embedder: this.embedder,
              content: doc,
            });
            return {
              text: doc,
              embedding: result[0].embedding,
            };
          })
        );

        await fs.writeFile(
          this.storePath,
          JSON.stringify(embeddings, null, 2)
        );
      }

      async search(query: string, limit: number = 5) {
        const queryEmbedding = await ai.embed({
          embedder: this.embedder,
          content: query,
        });

        const data = JSON.parse(await fs.readFile(this.storePath, 'utf-8'));
        
        // Simple cosine similarity
        const results = data
          .map((item: any) => ({
            ...item,
            similarity: this.cosineSimilarity(
              queryEmbedding[0].embedding,
              item.embedding
            ),
          }))
          .sort((a: any, b: any) => b.similarity - a.similarity)
          .slice(0, limit);

        return results;
      }

      private cosineSimilarity(a: number[], b: number[]): number {
        const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);
        const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
        const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
        return dotProduct / (magnitudeA * magnitudeB);
      }
    }

    // Usage
    const localStore = new DevLocalVectorStore(
      './dev-vector-store.json',
      googleAI.embedder('text-embedding-004')
    );
    ```
</LanguageContent>

<LanguageContent lang="go">
Go doesn't have a dedicated dev local vector store plugin, but you can create a simple file-based solution:

    ```bash
    go get github.com/firebase/genkit/go/genkit
    ```

    Create a simple local vector store:

    ```go
    package main

    import (
        "context"
        "encoding/json"
        "fmt"
        "math"
        "os"
        "sort"
        
        "github.com/firebase/genkit/go/ai"
        "github.com/firebase/genkit/go/genkit"
    )

    type VectorDocument struct {
        Text      string    `json:"text"`
        Embedding []float64 `json:"embedding"`
    }

    type DevLocalVectorStore struct {
        storePath string
        embedder  ai.Embedder
    }

    func NewDevLocalVectorStore(storePath string, embedder ai.Embedder) *DevLocalVectorStore {
        return &DevLocalVectorStore{
            storePath: storePath,
            embedder:  embedder,
        }
    }

    func (store *DevLocalVectorStore) Index(ctx context.Context, documents []string) error {
        var vectorDocs []VectorDocument

        for _, doc := range documents {
            resp, err := ai.Embed(ctx, store.embedder, ai.WithDocs(doc))
            if err != nil {
                return err
            }

            vectorDocs = append(vectorDocs, VectorDocument{
                Text:      doc,
                Embedding: resp.Embeddings[0].Embedding,
            })
        }

        data, err := json.MarshalIndent(vectorDocs, "", "  ")
        if err != nil {
            return err
        }

        return os.WriteFile(store.storePath, data, 0644)
    }

    func (store *DevLocalVectorStore) Search(ctx context.Context, query string, limit int) ([]VectorDocument, error) {
        // Get query embedding
        queryResp, err := ai.Embed(ctx, store.embedder, ai.WithDocs(query))
        if err != nil {
            return nil, err
        }
        queryEmbedding := queryResp.Embeddings[0].Embedding

        // Load stored documents
        data, err := os.ReadFile(store.storePath)
        if err != nil {
            return nil, err
        }

        var docs []VectorDocument
        if err := json.Unmarshal(data, &docs); err != nil {
            return nil, err
        }

        // Calculate similarities and sort
        type result struct {
            doc        VectorDocument
            similarity float64
        }

        var results []result
        for _, doc := range docs {
            similarity := cosineSimilarity(queryEmbedding, doc.Embedding)
            results = append(results, result{doc: doc, similarity: similarity})
        }

        sort.Slice(results, func(i, j int) bool {
            return results[i].similarity > results[j].similarity
        })

        // Return top results
        if limit > len(results) {
            limit = len(results)
        }

        var topDocs []VectorDocument
        for i := 0; i < limit; i++ {
            topDocs = append(topDocs, results[i].doc)
        }

        return topDocs, nil
    }

    func cosineSimilarity(a, b []float64) float64 {
        var dotProduct, magnitudeA, magnitudeB float64

        for i := range a {
            dotProduct += a[i] * b[i]
            magnitudeA += a[i] * a[i]
            magnitudeB += b[i] * b[i]
        }

        magnitudeA = math.Sqrt(magnitudeA)
        magnitudeB = math.Sqrt(magnitudeB)

        if magnitudeA == 0 || magnitudeB == 0 {
            return 0
        }

        return dotProduct / (magnitudeA * magnitudeB)
    }
    ```
</LanguageContent>

<LanguageContent lang="python">
Install the Dev Local Vector Store plugin:

    ```bash
    pip install genkit-plugin-dev-local-vectorstore
    ```

    Configure the plugin:

    ```python
    from genkit.ai import Genkit
    from genkit.plugins.dev_local_vectorstore import DevLocalVectorStore
    from genkit.plugins.google_genai import GoogleGenAI

    ai = Genkit(
        plugins=[
            GoogleGenAI(),
            DevLocalVectorStore(
                name='my_vectorstore',
                embedder='googleai/text-embedding-004',
            ),
        ],
    )
    ```
</LanguageContent>

## Basic Usage

### Indexing Documents

<LanguageContent lang="js">
```ts
    // Index documents in the local store
    const documents = [
        'Machine learning is a subset of artificial intelligence.',
        'Deep learning uses neural networks with multiple layers.',
        'Natural language processing enables computers to understand text.',
        'Computer vision allows machines to interpret visual information.',
    ];

    await localStore.index(documents);
    console.log('Documents indexed successfully');
    ```
</LanguageContent>

<LanguageContent lang="go">
```go
    // Initialize the local store
    embedder := googleAIPlugin.Embedder(g, "text-embedding-004")
    localStore := NewDevLocalVectorStore("./dev-vector-store.json", embedder)

    // Index documents
    documents := []string{
        "Machine learning is a subset of artificial intelligence.",
        "Deep learning uses neural networks with multiple layers.",
        "Natural language processing enables computers to understand text.",
        "Computer vision allows machines to interpret visual information.",
    }

    err := localStore.Index(ctx, documents)
    if err != nil {
        log.Fatal(err)
    }
    fmt.Println("Documents indexed successfully")
    ```
</LanguageContent>

<LanguageContent lang="python">
```python
    from genkit.types import Document

    # Prepare documents
    data_list = [
        'Machine learning is a subset of artificial intelligence.',
        'Deep learning uses neural networks with multiple layers.',
        'Natural language processing enables computers to understand text.',
        'Computer vision allows machines to interpret visual information.',
    ]

    # Convert to Genkit documents
    genkit_docs = [Document.from_text(text=item) for item in data_list]

    # Index documents
    await DevLocalVectorStore.index('my_vectorstore', genkit_docs)
    print("Documents indexed successfully")
    ```
</LanguageContent>

### Retrieving Documents

<LanguageContent lang="js">
```ts
    // Search for similar documents
    const query = 'What is artificial intelligence?';
    const results = await localStore.search(query, 3);

    console.log('Search results:');
    results.forEach((result, index) => {
        console.log(`${index + 1}. ${result.text} (similarity: ${result.similarity.toFixed(3)})`);
    });

    // Use in RAG workflow
    async function ragQuery(question: string) {
        const retrievedDocs = await localStore.search(question, 3);
        const context = retrievedDocs.map(doc => doc.text).join('\n\n');
        
        const response = await ai.generate({
            model: googleAI.model('gemini-1.5-flash'),
            prompt: `Context: ${context}\n\nQuestion: ${question}\n\nAnswer:`,
        });
        
        return response.text;
    }

    const answer = await ragQuery('What is machine learning?');
    console.log('Answer:', answer);
    ```
</LanguageContent>

<LanguageContent lang="go">
```go
    // Search for similar documents
    query := "What is artificial intelligence?"
    results, err := localStore.Search(ctx, query, 3)
    if err != nil {
        log.Fatal(err)
    }

    fmt.Println("Search results:")
    for i, result := range results {
        fmt.Printf("%d. %s\n", i+1, result.Text)
    }

    // Use in RAG workflow
    func ragQuery(ctx context.Context, question string) (string, error) {
        retrievedDocs, err := localStore.Search(ctx, question, 3)
        if err != nil {
            return "", err
        }

        var contextParts []string
        for _, doc := range retrievedDocs {
            contextParts = append(contextParts, doc.Text)
        }
        context := strings.Join(contextParts, "\n\n")

        resp, err := genkit.Generate(ctx, g,
            ai.WithModel(googleAIPlugin.Model(g, "gemini-1.5-flash")),
            ai.WithPrompt(fmt.Sprintf("Context: %s\n\nQuestion: %s\n\nAnswer:", context, question)),
        )
        if err != nil {
            return "", err
        }

        return resp.Text(), nil
    }

    answer, err := ragQuery(ctx, "What is machine learning?")
    if err != nil {
        log.Fatal(err)
    }
    fmt.Printf("Answer: %s\n", answer)
    ```
</LanguageContent>

<LanguageContent lang="python">
```python
    from genkit.types import Document

    # Search for similar documents
    async def search_documents(query: str):
        query_doc = Document.from_text(query)
        
        results = await ai.retrieve(
            query=query_doc,
            retriever='my_vectorstore',
        )
        
        return results

    # Use in RAG workflow
    async def rag_query(question: str):
        query_doc = Document.from_text(question)
        
        # Retrieve relevant documents
        retrieved_docs = await ai.retrieve(
            query=query_doc,
            retriever='my_vectorstore',
        )
        
        # Prepare context
        context = "\n\n".join([doc.content[0].text for doc in retrieved_docs])
        
        # Generate answer
        response = await ai.generate(
            model="googleai/gemini-1.5-flash",
            prompt=f"Context: {context}\n\nQuestion: {question}\n\nAnswer:",
        )
        
        return response.text

    # Example usage
    results = await search_documents("What is artificial intelligence?")
    print("Search results:")
    for i, doc in enumerate(results, 1):
        print(f"{i}. {doc.content[0].text}")

    answer = await rag_query("What is machine learning?")
    print(f"Answer: {answer}")
    ```
</LanguageContent>

## Advanced Configuration

### Custom Storage Location

<LanguageContent lang="js">
```ts
    // Custom storage path
    const customStore = new DevLocalVectorStore(
        './data/custom-vector-store.json',
        googleAI.embedder('text-embedding-004')
    );

    // Multiple stores for different domains
    const techStore = new DevLocalVectorStore(
        './data/tech-docs.json',
        googleAI.embedder('text-embedding-004')
    );

    const generalStore = new DevLocalVectorStore(
        './data/general-docs.json',
        googleAI.embedder('text-embedding-004')
    );
    ```
</LanguageContent>

<LanguageContent lang="go">
```go
    // Custom storage paths
    techStore := NewDevLocalVectorStore("./data/tech-docs.json", embedder)
    generalStore := NewDevLocalVectorStore("./data/general-docs.json", embedder)

    // Index different types of content
    techDocs := []string{
        "API documentation for REST endpoints",
        "Database schema design principles",
        "Microservices architecture patterns",
    }

    generalDocs := []string{
        "Company policies and procedures",
        "Meeting notes and summaries",
        "Project planning documents",
    }

    err := techStore.Index(ctx, techDocs)
    if err != nil {
        log.Fatal(err)
    }

    err = generalStore.Index(ctx, generalDocs)
    if err != nil {
        log.Fatal(err)
    }
    ```
</LanguageContent>

<LanguageContent lang="python">
```python
    # Multiple vector stores for different domains
    ai = Genkit(
        plugins=[
            GoogleGenAI(),
            DevLocalVectorStore(
                name='tech_docs',
                embedder='googleai/text-embedding-004',
            ),
            DevLocalVectorStore(
                name='general_docs',
                embedder='googleai/text-embedding-004',
            ),
        ],
    )

    # Index different types of content
    tech_docs = [
        Document.from_text("API documentation for REST endpoints"),
        Document.from_text("Database schema design principles"),
        Document.from_text("Microservices architecture patterns"),
    ]

    general_docs = [
        Document.from_text("Company policies and procedures"),
        Document.from_text("Meeting notes and summaries"),
        Document.from_text("Project planning documents"),
    ]

    await DevLocalVectorStore.index('tech_docs', tech_docs)
    await DevLocalVectorStore.index('general_docs', general_docs)
    ```
</LanguageContent>

### Batch Operations

<LanguageContent lang="js">
```ts
    // Batch indexing for better performance
    async function batchIndex(documents: string[], batchSize: number = 10) {
        for (let i = 0; i < documents.length; i += batchSize) {
            const batch = documents.slice(i, i + batchSize);
            await localStore.index(batch);
            console.log(`Indexed batch ${Math.floor(i / batchSize) + 1}`);
        }
    }

    // Large document set
    const largeDocumentSet = [
        // ... hundreds of documents
    ];

    await batchIndex(largeDocumentSet, 20);
    ```
</LanguageContent>

<LanguageContent lang="go">
```go
    // Batch indexing function
    func batchIndex(ctx context.Context, store *DevLocalVectorStore, documents []string, batchSize int) error {
        for i := 0; i < len(documents); i += batchSize {
            end := i + batchSize
            if end > len(documents) {
                end = len(documents)
            }
            
            batch := documents[i:end]
            err := store.Index(ctx, batch)
            if err != nil {
                return err
            }
            
            fmt.Printf("Indexed batch %d\n", (i/batchSize)+1)
        }
        return nil
    }

    // Usage
    largeDocumentSet := []string{
        // ... hundreds of documents
    }

    err := batchIndex(ctx, localStore, largeDocumentSet, 20)
    if err != nil {
        log.Fatal(err)
    }
    ```
</LanguageContent>

<LanguageContent lang="python">
```python
    # Batch indexing for large document sets
    async def batch_index(store_name: str, documents: list[str], batch_size: int = 20):
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            genkit_docs = [Document.from_text(text=doc) for doc in batch]
            
            await DevLocalVectorStore.index(store_name, genkit_docs)
            print(f"Indexed batch {(i // batch_size) + 1}")

    # Large document set
    large_document_set = [
        # ... hundreds of documents
    ]

    await batch_index('my_vectorstore', large_document_set, 20)
    ```
</LanguageContent>

## Best Practices

### Development Workflow

1. **Start Simple**: Use the dev local vector store for initial prototyping
2. **Test Locally**: Validate your RAG pipeline before moving to production
3. **Iterate Quickly**: Make changes and test without external dependencies
4. **Document Structure**: Establish consistent document formats early

### Performance Considerations

1. **Document Size**: Keep documents reasonably sized (500-1000 tokens)
2. **Index Size**: Monitor file size for large document sets
3. **Search Limits**: Use appropriate limits for search results
4. **Batch Processing**: Use batch operations for large datasets

### Migration to Production

<LanguageContent lang="js">
```ts
    // Environment-based vector store selection
    const isProduction = process.env.NODE_ENV === 'production';

    const vectorStore = isProduction
        ? new PineconeVectorStore({
            apiKey: process.env.PINECONE_API_KEY,
            indexName: 'production-index',
        })
        : new DevLocalVectorStore(
            './dev-vector-store.json',
            googleAI.embedder('text-embedding-004')
        );

    // Same interface for both stores
    await vectorStore.index(documents);
    const results = await vectorStore.search(query, 5);
    ```
</LanguageContent>

<LanguageContent lang="go">
```go
    // Environment-based store selection
    var store VectorStore

    if os.Getenv("ENVIRONMENT") == "production" {
        store = NewPineconeVectorStore(os.Getenv("PINECONE_API_KEY"), "production-index")
    } else {
        store = NewDevLocalVectorStore("./dev-vector-store.json", embedder)
    }

    // Same interface for both stores
    err := store.Index(ctx, documents)
    results, err := store.Search(ctx, query, 5)
    ```
</LanguageContent>

<LanguageContent lang="python">
```python
    import os

    # Environment-based configuration
    if os.getenv("ENVIRONMENT") == "production":
        ai = Genkit(
            plugins=[
                GoogleGenAI(),
                PineconeVectorStore(
                    name='production_store',
                    api_key=os.getenv("PINECONE_API_KEY"),
                    index_name='production-index',
                    embedder='googleai/text-embedding-004',
                ),
            ],
        )
        store_name = 'production_store'
    else:
        ai = Genkit(
            plugins=[
                GoogleGenAI(),
                DevLocalVectorStore(
                    name='dev_store',
                    embedder='googleai/text-embedding-004',
                ),
            ],
        )
        store_name = 'dev_store'

    # Same interface for both environments
    query_doc = Document.from_text("search query")
    results = await ai.retrieve(query=query_doc, retriever=store_name)
    ```
</LanguageContent>

## Limitations

1. **Not for Production**: Designed for development and testing only
2. **No Persistence**: Data is stored in local files
3. **Single Machine**: Cannot be shared across multiple instances
4. **Limited Scalability**: Performance degrades with very large datasets
5. **No Advanced Features**: Lacks filtering, metadata search, and other advanced capabilities

## Next Steps

- Start with the Dev Local Vector Store for prototyping
- Learn about [RAG implementation](/unified-docs/rag) for building complete workflows
- Explore production vector databases like [Pinecone](/unified-docs/vector-databases/pinecone) or [ChromaDB](/unified-docs/vector-databases/chromadb)
- See [deployment guides](/unified-docs/deployment) for moving to production
