---
title: Model Provider Overview
description: Overview of supported AI model providers across JavaScript, Go, and Python implementations of Genkit.
---

import LanguageSelector from '../../../../components/LanguageSelector.astro';
import CopyMarkdownButton from '../../../../components/CopyMarkdownButton.astro';
import LanguageContent from '../../../../components/LanguageContent.astro';

<div style="display: flex; justify-content: space-between; align-items: center; gap: 1rem; margin: 1rem 0 1rem 0;">
  <LanguageSelector />
  <CopyMarkdownButton />
</div>

Genkit provides a unified interface to work with various AI providers and models. This page provides an overview of all supported model providers across JavaScript, Go, and Python implementations.

<LanguageContent lang="js">

## JavaScript Model Providers

Genkit for JavaScript offers the most comprehensive set of model provider integrations, including both official and community-maintained plugins.

### Google AI & Vertex AI

**Google Generative AI Plugin** - Direct access to Google's Gemini models through the Gemini Developer API using API key authentication.

- **Installation**: `npm i --save @genkit-ai/google-genai`
- **Models**: Gemini 2.5 Flash, Gemini 2.0 Pro, Gemini 1.5 Pro/Flash, Imagen2/3, text-embedding models
- **Features**: Text generation, embeddings, image generation, video generation (Veo), text-to-speech
- **Authentication**: API key (GEMINI_API_KEY or GOOGLE_API_KEY)

**Vertex AI Plugin** - Enterprise-grade access to Google's models with advanced features.

- **Installation**: `npm i --save @genkit-ai/google-genai` (Gemini Models) or `npm install @genkit-ai/vertexai` (Model Garden, Vector Search)
- **Models**: All Gemini models, Imagen models, Model Garden access (Claude 3, Llama 3.1, Mistral)
- **Features**: Grounding, context caching, Vector Search, evaluation metrics
- **Authentication**: Google Cloud Application Default Credentials

### OpenAI

**OpenAI Plugin** - Direct integration with OpenAI's API.

- **Models**: GPT-4, GPT-4 Turbo, GPT-3.5 Turbo, DALL-E 3, Whisper
- **Features**: Text generation, image generation, audio transcription

**OpenAI-Compatible Plugin** - Works with OpenAI-compatible APIs and services.

- **Models**: Any OpenAI-compatible API endpoints
- **Features**: Flexible configuration for various providers

### Anthropic (Claude)

**Direct Access**: Available through Vertex AI Model Garden (official) or community plugins.

- **Models**: Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku
- **Features**: Text generation, reasoning capabilities

### xAI (Grok)

**xAI Plugin** - Direct integration with xAI's Grok models.

- **Models**: Grok family of models
- **Features**: Text generation with xAI's reasoning capabilities

### DeepSeek

**DeepSeek Plugin** - Integration with DeepSeek's reasoning models.

- **Models**: DeepSeek Chat, DeepSeek Reasoner
- **Features**: Advanced reasoning and problem-solving capabilities

### Ollama (Local Models)

**Ollama Plugin** - Run open-source models locally.

- **Models**: Gemma 2, Llama 3, Mistral, CodeLlama, and any model in the Ollama library
- **Features**: Local inference, privacy-focused, customizable model configurations
- **Requirements**: Self-hosted Ollama server

### Community Providers

The JavaScript ecosystem includes many community-maintained providers:

- **[Anthropic Plugin](https://thefireco.github.io/genkit-pluginsdocs/integrations/genkitx-anthropic)** - Direct Claude 3 family access
- **[Azure OpenAI Plugin](https://thefireco.github.io/genkit-pluginsdocs/integrations/genkitx-azure-openai)** - GPT models through Azure
- **[Cohere Plugin](https://thefireco.github.io/genkit-pluginsdocs/integrations/genkitx-cohere)** - Command R family of models
- **[Mistral Plugin](https://thefireco.github.io/genkit-pluginsdocs/integrations/genkitx-mistral)** - Mistral family of models
- **[Groq Plugin](https://thefireco.github.io/genkit-pluginsdocs/integrations/genkitx-groq)** - Fast inference for open models

### Finding More Providers

Search for packages tagged with `genkit-model` on [npm](https://www.npmjs.com/search?q=keywords:genkit-model) to discover additional community providers.

## Getting Started

1. Choose a provider based on your needs (API access, local inference, specific models)
2. Install the appropriate plugin package
3. Configure authentication (API keys or cloud credentials)
4. Start generating content with your chosen models

## Next Steps

- [Get started](/docs/get-started) with Genkit
- Learn about [generating content](/docs/models) with AI models
- Explore specific provider documentation for detailed setup instructions

</LanguageContent>

<LanguageContent lang="go">

## Go Model Providers

Genkit for Go provides access to Google's AI models and local inference options through a focused set of integrations.

### Google AI & Vertex AI

**Google Generative AI Plugin** - Access to Google's Gemini models through both the Gemini Developer API and Vertex AI.

- **Package**: `github.com/firebase/genkit/go/plugins/googlegenai`
- **Models**: Gemini 2.5 Flash, Gemini 2.0 Pro, Gemini 1.5 Pro/Flash, text-embedding models
- **Features**: Text generation, embeddings
- **Authentication**: 
  - API key for Gemini Developer API (GEMINI_API_KEY)
  - Google Cloud Application Default Credentials for Vertex AI

**Configuration Options**:
- `googlegenai.GoogleAI{}` - For Gemini Developer API access
- `googlegenai.VertexAI{}` - For Vertex AI access with enterprise features

### Ollama (Local Models)

**Ollama Plugin** - Run open-source models locally.

- **Models**: Gemma 2, Llama 3, Mistral, CodeLlama, and any model in the Ollama library
- **Features**: Local inference, privacy-focused, customizable model configurations
- **Requirements**: Self-hosted Ollama server

### OpenAI-Compatible APIs

**OpenAI-Compatible Plugin** - Works with OpenAI and compatible services.

- **Models**: GPT-4, GPT-4 Turbo, GPT-3.5 Turbo, and other OpenAI-compatible endpoints
- **Features**: Text generation, flexible API configuration

### Advanced Features

Advanced features like Vector Search, Model Garden access, and evaluation metrics require custom implementation using the Google Cloud SDK directly. See the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs) for implementation details.

### Community Providers

Community plugins for Go are available. Check the [third-party plugins overview](/godocs/integrations/third-party-plugins) for the latest options.

### Finding More Providers

Search for packages with `genkit` in the name on [pkg.go.dev](https://pkg.go.dev/search?q=genkit) to find Go-specific providers.

## Getting Started

1. Import the appropriate plugin package
2. Initialize Genkit with the plugin using `genkit.WithPlugins()`
3. Configure authentication (API keys or cloud credentials)
4. Start generating content with your chosen models

## Next Steps

- [Get started](/docs/get-started) with Genkit
- Learn about [generating content](/docs/models) with AI models
- Explore specific provider documentation for detailed setup instructions

</LanguageContent>

<LanguageContent lang="python">

## Python Model Providers

Genkit for Python provides access to Google's AI models and local inference options through a growing set of integrations.

### Google AI & Vertex AI

**Google GenAI Plugin** - Access to Google's Gemini models through both the Gemini Developer API and Vertex AI.

- **Package**: `genkit-plugin-google-genai`
- **Installation**: `pip3 install genkit-plugin-google-genai`
- **Models**: Gemini 2.5 Flash, Gemini 2.0 Pro, Gemini 1.5 Pro/Flash, Imagen models, text-embedding models
- **Features**: Text generation, embeddings, image generation
- **Authentication**:
  - API key for Gemini Developer API (GEMINI_API_KEY)
  - Google Cloud Application Default Credentials for Vertex AI

**Configuration Options**:
- `GoogleAI()` - For Gemini Developer API access
- `VertexAI()` - For Vertex AI access with enterprise authentication

### Ollama (Local Models)

**Ollama Plugin** - Run open-source models locally.

- **Models**: Gemma 2, Llama 3, Mistral, CodeLlama, and any model in the Ollama library
- **Features**: Local inference, privacy-focused, customizable model configurations
- **Requirements**: Self-hosted Ollama server

### Advanced Features

Advanced Vertex AI features like Vector Search, Model Garden access, and evaluation metrics require custom implementation using the Google Cloud SDK directly. See the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs) for implementation details.

### Community Providers

Community plugins for Python are emerging. Search for packages tagged with `genkit-model` on [PyPI](https://pypi.org/search/?q=genkit-model) to discover Python-specific providers.

### Finding More Providers

Search for packages tagged with `genkit-model` on [PyPI](https://pypi.org/search/?q=genkit-model) to discover additional community providers.

## Getting Started

1. Install the appropriate plugin package using pip
2. Initialize Genkit with the plugin in your configuration
3. Configure authentication (API keys or cloud credentials)
4. Start generating content with your chosen models

## Next Steps

- [Get started](/docs/get-started) with Genkit
- Learn about [generating content](/docs/models) with AI models
- Explore specific provider documentation for detailed setup instructions

</LanguageContent>