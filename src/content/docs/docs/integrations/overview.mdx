---
title: AI Provider Overview
description: Overview of supported AI providers and models across JavaScript, Go, and Python implementations of Genkit.
---

import LanguageSelector from '../../../../components/LanguageSelector.astro';
import CopyMarkdownButton from '../../../../components/CopyMarkdownButton.astro';
import LanguageContent from '../../../../components/LanguageContent.astro';

<div style="display: flex; justify-content: space-between; align-items: center; gap: 1rem; margin: 1rem 0 1rem 0;">
  <LanguageSelector />
  <CopyMarkdownButton />
</div>

Genkit provides a unified interface to work with various AI providers and models. This page lists all supported providers across JavaScript, Go, and Python implementations.

## Officially Supported Providers

These providers are maintained by the Genkit team:

### Google AI & Vertex AI

<LanguageContent lang="js">
- **Google AI Plugin** - Direct access to Google's Gemini models
- **Vertex AI Plugin** - Enterprise-grade access to Google's models and third-party models through Vertex AI

**Supported Models:**
- Gemini 2.5 Flash, Gemini 2.0 Pro, Gemini 1.5 Pro/Flash
- Imagen2 and Imagen3 (image generation)
- Claude 3 family (through Vertex AI Model Garden)
</LanguageContent>

<LanguageContent lang="go">
- **Google Generative AI Plugin** - Direct access to Google's Gemini models
- **Google Cloud Plugin** - Access to Vertex AI and other Google Cloud AI services

**Supported Models:**
- Gemini 2.5 Flash, Gemini 2.0 Pro, Gemini 1.5 Pro/Flash
- Imagen2 and Imagen3 (image generation)
- Claude 3 family (through Vertex AI Model Garden)
</LanguageContent>

<LanguageContent lang="python">
- **Google GenAI Plugin** - Direct access to Google's Gemini models

**Supported Models:**
- Gemini 2.5 Flash, Gemini 2.0 Pro, Gemini 1.5 Pro/Flash
</LanguageContent>

### OpenAI

<LanguageContent lang="js">
- **OpenAI Plugin** - Direct integration with OpenAI's API
- **OpenAI-Compatible Plugin** - Works with OpenAI-compatible APIs

**Supported Models:**
- GPT-4, GPT-4 Turbo, GPT-3.5 Turbo
- DALL-E 3 (image generation)
- Whisper (audio transcription)
</LanguageContent>

<LanguageContent lang="go">
- **OpenAI-Compatible APIs Plugin** - Works with OpenAI and compatible services

**Supported Models:**
- GPT-4, GPT-4 Turbo, GPT-3.5 Turbo
- DALL-E 3 (image generation)
- Whisper (audio transcription)
</LanguageContent>

<LanguageContent lang="python">
OpenAI support varies by implementation - check specific documentation for your Python setup.
</LanguageContent>

### Anthropic (Claude)

<LanguageContent lang="js">
- Available through Vertex AI Model Garden
- Community plugin available (see Community Providers section)

**Supported Models:**
- Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku
</LanguageContent>

<LanguageContent lang="go">
- Available through Vertex AI Model Garden

**Supported Models:**
- Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku
</LanguageContent>

<LanguageContent lang="python">
Support varies by implementation - check specific documentation for your Python setup.
</LanguageContent>

### xAI (Grok)

<LanguageContent lang="js">
- **xAI Plugin** - Direct integration with xAI's Grok models

**Supported Models:**
- Grok family of models
</LanguageContent>

<LanguageContent lang="go">
Support varies by implementation - check specific documentation for your Go setup.
</LanguageContent>

<LanguageContent lang="python">
Support varies by implementation - check specific documentation for your Python setup.
</LanguageContent>

### DeepSeek

<LanguageContent lang="js">
- **DeepSeek Plugin** - Integration with DeepSeek's reasoning models

**Supported Models:**
- DeepSeek Chat, DeepSeek Reasoner
</LanguageContent>

<LanguageContent lang="go">
Support varies by implementation - check specific documentation for your Go setup.
</LanguageContent>

<LanguageContent lang="python">
Support varies by implementation - check specific documentation for your Python setup.
</LanguageContent>

### Ollama (Local Models)

<LanguageContent lang="js">
- **Ollama Plugin** - Run open-source models locally

**Supported Models:**
- Gemma 2, Llama 3, Mistral, CodeLlama
- Any model available in the Ollama model library
- Requires self-hosted Ollama server
</LanguageContent>

<LanguageContent lang="go">
- **Ollama Plugin** - Run open-source models locally

**Supported Models:**
- Gemma 2, Llama 3, Mistral, CodeLlama
- Any model available in the Ollama model library
- Requires self-hosted Ollama server
</LanguageContent>

<LanguageContent lang="python">
- **Ollama Plugin** - Run open-source models locally

**Supported Models:**
- Gemma 2, Llama 3, Mistral, CodeLlama
- Any model available in the Ollama model library
- Requires self-hosted Ollama server
</LanguageContent>

## Community Providers

<LanguageContent lang="js">
These community-maintained providers offer additional integration options:

- **[Anthropic Plugin](https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic)** - Direct Claude 3 family access
- **[Azure OpenAI Plugin](https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-azure-openai)** - GPT models through Azure
- **[Cohere Plugin](https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-cohere)** - Command R family of models
- **[Mistral Plugin](https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-mistral)** - Mistral family of models
- **[Groq Plugin](https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-groq)** - Fast inference for open models
</LanguageContent>

<LanguageContent lang="go">
Community plugins for Go are available - check the [third-party plugins overview](/go/docs/plugins/third-party-plugins) for the latest options.
</LanguageContent>

<LanguageContent lang="python">
Community plugins for Python are emerging - check your package registry for packages tagged with `genkit-model`.
</LanguageContent>

## Finding More Providers

<LanguageContent lang="js">
Search for packages tagged with `genkit-model` on [npm](https://www.npmjs.com/search?q=keywords:genkit-model) to discover additional community providers.
</LanguageContent>

<LanguageContent lang="go">
Search for packages with `genkit` in the name on [pkg.go.dev](https://pkg.go.dev/search?q=genkit) to find Go-specific providers.
</LanguageContent>

<LanguageContent lang="python">
Search for packages tagged with `genkit-model` on [PyPI](https://pypi.org/search/?q=genkit-model) to discover Python-specific providers.
</LanguageContent>

## Provider Selection Guide

When choosing an AI provider, consider:

- **Model capabilities**: Text generation, image generation, multimodal input
- **Performance requirements**: Latency, throughput, cost
- **Deployment constraints**: Cloud vs. local, data residency requirements
- **Language support**: Availability in your preferred Genkit implementation

## Next Steps

- [Get started](/docs/get-started) with Genkit
- Learn about [generating content](/docs/models) with AI models
- Explore specific provider documentation for setup instructions
