---
title: Pause generation using interrupts
description: Learn how to use interrupts in Genkit to pause and resume LLM generation, enabling human-in-the-loop interactions, asynchronous processing, and controlled task completion.
---

import ExampleLink from '@/components/ExampleLink.astro';
import LanguageSelector from '../../../components/LanguageSelector.astro';
import CopyMarkdownButton from '../../../components/CopyMarkdownButton.astro';
import LanguageContent from '../../../components/LanguageContent.astro';
import { Tabs, TabItem } from '@astrojs/starlight/components';

<div style="display: flex; justify-content: space-between; align-items: center; gap: 1rem; margin: 1rem 0 1rem 0;">
  <LanguageSelector supportedLanguages="js go python" />
  <CopyMarkdownButton />
</div>

<LanguageContent lang="go">

_Interrupts_ are a special kind of [tool](/docs/tool-calling) that can pause the
LLM generation-and-tool-calling loop to return control back to you. When
you're ready, you can then _resume_ generation by sending _replies_ that the LLM
processes for further generation.

The most common uses for interrupts fall into a few categories:

- **Human-in-the-Loop:** Enabling the user of an interactive AI
  to clarify needed information or confirm the LLM's action
  before it is completed, providing a measure of safety and confidence.
- **Async Processing:** Starting an asynchronous task that can only be
  completed out-of-band, such as sending an approval notification to
  a human reviewer or kicking off a long-running background process.
- **Exit from an Autonomous Task:** Providing the model a way
  to mark a task as complete, in a workflow that might iterate through
  a long series of tool calls.

## Before you begin

All of the examples documented here assume that you have already set up a
project with Genkit dependencies installed. If you want to run the code
examples on this page, first complete the steps in the
[Get started](/docs/get-started/) guide.

Before diving too deeply, you should also be familiar with the following
concepts:

- [Generating content](/docs/models/) with AI models.
- Genkit's system for [defining input and output schemas](/docs/flows/).
- General methods of [tool-calling](/docs/tool-calling/).

## Overview of interrupts

At a high level, this is what an interrupt looks like when
interacting with an LLM:

1.  The calling application prompts the LLM with a request. The prompt includes
    a list of tools, including at least one for an interrupt that the LLM
    can use to generate a response.
2.  The LLM generates either a complete response or a tool call request
    in a specific format. To the LLM, an interrupt call looks like any
    other tool call.
3.  If the LLM calls an interrupting tool,
    the Genkit library automatically pauses generation rather than immediately
    passing responses back to the model for additional processing.
4.  The developer checks whether an interrupt call is made, and performs whatever
    task is needed to collect the information needed for the interrupt response.
5.  The developer resumes generation by passing an interrupt response to the
    model. This action triggers a return to Step 2.

## Defining tools with interrupts

Use `genkit.DefineTool()` and call `ai.InterruptWith()` to trigger a
strongly-typed interrupt. Define a struct to carry the interrupt metadata:

```go
// InterruptMetadata carries information about why the tool was interrupted.
type InterruptMetadata struct {
	Reason  string   `json:"reason"`
	Choices []string `json:"choices,omitempty"`
}

askQuestion := genkit.DefineTool(g, "askQuestion",
	"use this to ask the user a clarifying question",
	func(ctx *ai.ToolContext, input QuestionInput) (string, error) {
		return "", ai.InterruptWith(ctx, InterruptMetadata{
			Reason:  "need_clarification",
			Choices: input.Choices,
		})
	},
)
```

### Use interrupts

Interrupts are passed into the `WithTools()` option when generating content, just like
other types of tools:

```go
resp, err := genkit.Generate(ctx, g,
	ai.WithPrompt("Ask me a movie trivia question."),
	ai.WithTools(askQuestion),
)
```

Genkit immediately returns a response on receipt of an interrupt tool call.

### Respond to interrupts

Check the response for interrupts and handle them. Use `ai.InterruptAs()` to
extract strongly-typed metadata from the interrupt:

```go
// Check if generation was interrupted
if resp.FinishReason == ai.FinishReasonInterrupted {
	for _, interrupt := range resp.Interrupts() {
		if meta, ok := ai.InterruptAs[InterruptMetadata](interrupt); ok {
			fmt.Printf("Interrupt reason: %s\n", meta.Reason)
		}
	}
}
```

Responding to an interrupt is done using `tool.RespondWith()` and `ai.WithToolResponses()`
on a subsequent `Generate` call, passing in the existing message history:

```go
resp, err := genkit.Generate(ctx, g,
	ai.WithPrompt("Help me plan a backyard BBQ."),
	ai.WithSystem("Ask clarifying questions until you have a complete solution."),
	ai.WithTools(askQuestion),
)
if err != nil {
	return err
}

for resp.FinishReason == ai.FinishReasonInterrupted {
	var responses []*ai.Part

	for _, interrupt := range resp.Interrupts() {
		// Use RespondWith to provide a strongly-typed response
		part, err := askQuestion.RespondWith(interrupt, getUserAnswer(interrupt))
		if err != nil {
			return err
		}
		responses = append(responses, part)
	}

	resp, err = genkit.Generate(ctx, g,
		ai.WithMessages(resp.History()...),
		ai.WithTools(askQuestion),
		ai.WithToolResponses(responses...),
	)
	if err != nil {
		return err
	}
}

fmt.Println(resp.Text())
```

## Tools with restartable interrupts

Another common pattern is the need to _confirm_ an action that the LLM suggests
before actually performing it. For example, a payments app might want the user
to confirm certain kinds of transfers.

### Define a restartable tool

Use `ctx.IsResumed()` to check if the tool is being restarted after an interrupt:

```go
type TransferInput struct {
	ToAccount string  `json:"toAccount"`
	Amount    float64 `json:"amount"`
}

type TransferOutput struct {
	Status     string  `json:"status"`
	Message    string  `json:"message,omitempty"`
	NewBalance float64 `json:"newBalance,omitempty"`
}

type TransferInterrupt struct {
	Reason    string  `json:"reason"` // "insufficient_balance" or "confirm_large"
	ToAccount string  `json:"toAccount"`
	Amount    float64 `json:"amount"`
	Balance   float64 `json:"balance,omitempty"`
}

transferMoney := genkit.DefineTool(g, "transferMoney",
	"Transfers money to another account.",
	func(ctx *ai.ToolContext, input TransferInput) (TransferOutput, error) {
		// Check for insufficient balance
		if input.Amount > accountBalance {
			return TransferOutput{}, ai.InterruptWith(ctx, TransferInterrupt{
				Reason:  "insufficient_balance",
				ToAccount: input.ToAccount,
				Amount:    input.Amount,
				Balance:   accountBalance,
			})
		}

		// Require confirmation for large transfers (only on first execution)
		if !ctx.IsResumed() && input.Amount > 100 {
			return TransferOutput{}, ai.InterruptWith(ctx, TransferInterrupt{
				Reason:    "confirm_large",
				ToAccount: input.ToAccount,
				Amount:    input.Amount,
			})
		}

		// Execute the transfer
		accountBalance -= input.Amount
		return TransferOutput{"completed", "Transfer successful", accountBalance}, nil
	},
)
```

### Restart tools after interruption

Use `tool.RestartWith()` and `ai.WithToolRestarts()` to re-execute an interrupted
tool. You can optionally replace the input using `ai.WithNewInput()`:

```go
resp, err := genkit.Generate(ctx, g,
	ai.WithPrompt("Transfer $200 to account ABC123"),
	ai.WithTools(transferMoney),
)
if err != nil {
	return err
}

for resp.FinishReason == ai.FinishReasonInterrupted {
	var restarts, responses []*ai.Part

	for _, interrupt := range resp.Interrupts() {
		meta, ok := ai.InterruptAs[TransferInterrupt](interrupt)
		if !ok {
			continue
		}

		switch meta.Reason {
		case "insufficient_balance":
			if userConfirms("Transfer $%.2f instead?", meta.Balance) {
				// Restart with adjusted amount using WithNewInput
				part, err := transferMoney.RestartWith(interrupt,
					ai.WithNewInput(TransferInput{meta.ToAccount, meta.Balance}))
				if err != nil {
					return err
				}
				restarts = append(restarts, part)
			} else {
				// Provide a response directly without re-running the tool
				part, err := transferMoney.RespondWith(interrupt,
					TransferOutput{"cancelled", "Transfer cancelled by user.", accountBalance})
				if err != nil {
					return err
				}
				responses = append(responses, part)
			}

		case "confirm_large":
			if userConfirms("Confirm transfer of $%.2f?", meta.Amount) {
				// Simple restart (re-run with same input)
				part, err := transferMoney.RestartWith(interrupt)
				if err != nil {
					return err
				}
				restarts = append(restarts, part)
			} else {
				part, err := transferMoney.RespondWith(interrupt,
					TransferOutput{"cancelled", "Transfer cancelled by user.", accountBalance})
				if err != nil {
					return err
				}
				responses = append(responses, part)
			}
		}
	}

	resp, err = genkit.Generate(ctx, g,
		ai.WithMessages(resp.History()...),
		ai.WithTools(transferMoney),
		ai.WithToolRestarts(restarts...),
		ai.WithToolResponses(responses...),
	)
	if err != nil {
		return err
	}
}

fmt.Println(resp.Text())
```

### Access original input after replacement

When you use `ai.WithNewInput()`, you can access the original input inside
the tool using `ai.OriginalInputAs()`:

```go
transferMoney := genkit.DefineTool(g, "transferMoney",
	"Transfers money to another account.",
	func(ctx *ai.ToolContext, input TransferInput) (TransferOutput, error) {
		// ... interrupt logic ...

		accountBalance -= input.Amount
		message := fmt.Sprintf("Transferred $%.2f to %s", input.Amount, input.ToAccount)

		// Check if input was replaced and include original amount in message
		if orig, ok := ai.OriginalInputAs[TransferInput](ctx); ok {
			message = fmt.Sprintf("Transferred $%.2f to %s (adjusted from $%.2f)",
				input.Amount, input.ToAccount, orig.Amount)
		}

		return TransferOutput{"completed", message, accountBalance}, nil
	},
)
```

</LanguageContent>

<LanguageContent lang="python">

_Interrupts_ are a special kind of [tool](/docs/tool-calling) that can pause the
LLM generation-and-tool-calling loop to return control back to you. When
you're ready, you can then _resume_ generation by sending _replies_ that the LLM
processes for further generation.

The most common uses for interrupts fall into a few categories:

- **Human-in-the-Loop:** Enabling the user of an interactive AI
  to clarify needed information or confirm the LLM's action
  before it is completed, providing a measure of safety and confidence.
- **Async Processing:** Starting an asynchronous task that can only be
  completed out-of-band, such as sending an approval notification to
  a human reviewer or kicking off a long-running background process.
- **Exit from an Autonomous Task:** Providing the model a way
  to mark a task as complete, in a workflow that might iterate through
  a long series of tool calls.

## Before you begin

All of the examples documented here assume that you have already set up a
project with Genkit dependencies installed. If you want to run the code
examples on this page, first complete the steps in the
[Get started](/docs/get-started/) guide.

Before diving too deeply, you should also be familiar with the following
concepts:

- [Generating content](/docs/models/) with AI models.
- Genkit's system for [defining input and output schemas](/docs/flows/).
- General methods of [tool-calling](/docs/tool-calling/).

## Overview of interrupts

At a high level, this is what an interrupt looks like when
interacting with an LLM:

1.  The calling application prompts the LLM with a request. The prompt includes
    a list of tools, including at least one for an interrupt that the LLM
    can use to generate a response.
2.  The LLM generates either a complete response or a tool call request
    in a specific format. To the LLM, an interrupt call looks like any
    other tool call.
3.  If the LLM calls an interrupting tool,
    the Genkit library automatically pauses generation rather than immediately
    passing responses back to the model for additional processing.
4.  The developer checks whether an interrupt call is made, and performs whatever
    task is needed to collect the information needed for the interrupt response.
5.  The developer resumes generation by passing an interrupt response to the
    model. This action triggers a return to Step 2.

## Define manual-response interrupts

The most common kind of interrupt allows the LLM to request clarification from
the user, for example by asking a multiple-choice question.

For this use case, use the Genkit instance's `tool()` decorator with `ctx.interrupt()`:

```python
from genkit import Genkit, ToolRunContext, tool_response
from genkit.plugins.google_genai import GoogleAI
from pydantic import BaseModel, Field

ai = Genkit(
    plugins=[GoogleAI()],
    model='googleai/gemini-2.5-flash',
)

class QuestionInput(BaseModel):
    """Input schema for the question tool."""
    question: str = Field(description='the question to ask')
    choices: list[str] = Field(description='the choices to display to the user')
    allow_other: bool = Field(default=False, description='when true, allow write-ins')


@ai.tool()
def ask_question(input: QuestionInput, ctx: ToolRunContext) -> str:
    """Use this to ask the user a clarifying question."""
    # Interrupt with metadata that the caller can use.
    ctx.interrupt({
        'question': input.question,
        'choices': input.choices,
        'allow_other': input.allow_other,
    })
```

Note that the output type of an interrupt tool corresponds to the response data
you will provide when resuming, as opposed to something that will be automatically
populated by the tool function.

### Use interrupts

Interrupts are passed into the `tools` list when generating content, just like
other types of tools. You can pass both normal tools and interrupts to the
same `generate` call:

```python
response = await ai.generate(
    prompt='Ask me a movie trivia question.',
    tools=['ask_question'],
)
```

Genkit immediately returns a response on receipt of an interrupt tool call.

### Respond to interrupts

If you've passed one or more interrupts to your generate call, you
need to check the response for interrupts so that you can handle them:

```python
# You can check the 'finish_reason' attribute of the response
if response.finish_reason == 'interrupted':
    print("Generation interrupted.")

# Or you can check if any interrupt requests are on the response
if response.interrupts:
    print(f"Interrupts found: {len(response.interrupts)}")
    for interrupt in response.interrupts:
        # Access the interrupt metadata
        tool_input = interrupt.tool_request.input
        print(f"Question: {tool_input.get('question')}")
        print(f"Choices: {tool_input.get('choices')}")
```

Responding to an interrupt is done using the `tool_responses` option on a subsequent
`generate` call, making sure to pass in the existing message history. Use the
`tool_response` helper function to construct the response:

```python
from genkit import tool_response

# Get the user's answer (e.g., from user input)
user_answer = 'b'  # User selected option b

# Resume generation with the tool response
response = await ai.generate(
    messages=response.messages,
    tool_responses=[tool_response(response.interrupts[0], user_answer)],
    tools=['ask_question'],
)
```

### Handle multiple interrupts in a loop

For interactive applications, you'll often need to handle multiple interrupts
in a loop until the model completes its task:

```python
async def interactive_session():
    response = await ai.generate(
        prompt='Help me plan a backyard BBQ.',
        system='Ask clarifying questions until you have a complete solution.',
        tools=['ask_question'],
    )

    # Continue until no more interrupts
    while response.interrupts:
        answers = []

        # Handle all interrupts (multiple can occur at once)
        for interrupt in response.interrupts:
            tool_input = interrupt.tool_request.input
            question = tool_input.get('question', 'Unknown question')
            choices = tool_input.get('choices', [])

            # Display to user and get their answer
            print(f"\nQuestion: {question}")
            for i, choice in enumerate(choices):
                print(f"  {i + 1}. {choice}")

            user_input = input("Your answer: ")
            answers.append(tool_response(interrupt, user_input))

        # Resume generation with all answers
        response = await ai.generate(
            messages=response.messages,
            tool_responses=answers,
            tools=['ask_question'],
        )

    # No more interrupts - print final response
    print(f"\nFinal response: {response.text}")
```

## Tools with confirmation interrupts

Another common pattern is the need to _confirm_ an action that the LLM suggests
before actually performing it. For example, a payments app might want the user
to confirm certain kinds of transfers.

```python
class TransferInput(BaseModel):
    """Input for money transfer."""
    to_account: str = Field(description='destination account ID')
    amount: float = Field(description='amount to transfer')


class TransferOutput(BaseModel):
    """Output from money transfer."""
    status: str
    message: str


@ai.tool()
def transfer_money(input: TransferInput, ctx: ToolRunContext) -> TransferOutput:
    """Transfers money to another account."""
    # Require confirmation for large transfers
    if input.amount > 100:
        ctx.interrupt({
            'confirm': f'Please confirm transfer of ${input.amount:.2f} to {input.to_account}',
            'amount': input.amount,
            'to_account': input.to_account,
        })
        # Not reached on first call

    # Execute the transfer (only reached after confirmation or for small amounts)
    return TransferOutput(
        status='completed',
        message=f'Transferred ${input.amount:.2f} to {input.to_account}',
    )
```

To handle the confirmation:

```python
response = await ai.generate(
    prompt='Transfer $500 to account ABC123',
    tools=['transfer_money'],
)

if response.interrupts:
    interrupt = response.interrupts[0]
    confirm_msg = interrupt.tool_request.input.get('confirm')
    print(confirm_msg)

    if input("Confirm? (y/n): ").lower() == 'y':
        # Provide confirmation response
        response = await ai.generate(
            messages=response.messages,
            tool_responses=[tool_response(interrupt, {'confirmed': True})],
            tools=['transfer_money'],
        )
    else:
        # Provide rejection response
        response = await ai.generate(
            messages=response.messages,
            tool_responses=[tool_response(interrupt, {'status': 'cancelled', 'message': 'User rejected'})],
            tools=['transfer_money'],
        )

print(response.text)
```

## Using interrupts with flows

You can also use interrupts within flows for more structured applications:

```python
from genkit import Genkit, ToolRunContext, tool_response
from genkit.plugins.google_genai import GoogleAI
from pydantic import BaseModel, Field

ai = Genkit(plugins=[GoogleAI()])


class TriviaQuestion(BaseModel):
    """A trivia question with multiple choice answers."""
    question: str = Field(description='the trivia question')
    answers: list[str] = Field(description='multiple choice answers')


@ai.tool()
def present_question(input: TriviaQuestion, ctx: ToolRunContext) -> None:
    """Presents a trivia question to the user."""
    ctx.interrupt(input.model_dump())


@ai.flow()
async def play_trivia(theme: str) -> str:
    """Plays a trivia game on the given theme."""
    response = await ai.generate(
        prompt=f'Ask me a trivia question about {theme}.',
        tools=['present_question'],
    )

    if response.interrupts:
        interrupt = response.interrupts[0]
        question_data = interrupt.tool_request.input

        # In a real app, you'd get this from user input
        return f"Question: {question_data.get('question')}\nAnswers: {question_data.get('answers')}"

    return response.text
```

</LanguageContent>

<LanguageContent lang="js">

:::caution[Beta]
This feature of Genkit is in **Beta,** which means it is not yet part of Genkit's stable API. APIs of beta features may change in minor version releases.
:::

_Interrupts_ are a special kind of [tool](/docs/tool-calling) that can pause the
LLM generation-and-tool-calling loop to return control back to you. When
you're ready, you can then _resume_ generation by sending _replies_ that the LLM
processes for further generation.

The most common uses for interrupts fall into a few categories:

- **Human-in-the-Loop:** Enabling the user of an interactive AI
  to clarify needed information or confirm the LLM's action
  before it is completed, providing a measure of safety and confidence.
- **Async Processing:** Starting an asynchronous task that can only be
  completed out-of-band, such as sending an approval notification to
  a human reviewer or kicking off a long-running background process.
- **Exit from an Autonomous Task:** Providing the model a way
  to mark a task as complete, in a workflow that might iterate through
  a long series of tool calls.

<ExampleLink
  title="Human-in-the-Loop"
  description="See a live demo of how interrupts can allow the LLM to ask structured questions of the user."
  example="chatbot-hitl"
/>

## Before you begin

All of the examples documented here assume that you have already set up a
project with Genkit dependencies installed. If you want to run the code
examples on this page, first complete the steps in the
[Get started](/docs/get-started) guide.

Before diving too deeply, you should also be familiar with the following
concepts:

- [Generating content](/docs/models) with AI models.
- Genkit's system for [defining input and output schemas](/docs/flows).
- General methods of [tool-calling](/docs/tool-calling).

## Overview of interrupts

At a high level, this is what an interrupt looks like when
interacting with an LLM:

1. The calling application prompts the LLM with a request. The prompt includes
   a list of tools, including at least one for an interrupt that the LLM
   can use to generate a response.
2. The LLM generates either a complete response or a tool call request
   in a specific format. To the LLM, an interrupt call looks like any
   other tool call.
3. If the LLM calls an interrupt tool,
   the Genkit library automatically pauses generation rather than immediately
   passing responses back to the model for additional processing.
4. The developer checks whether an interrupt call is made, and performs whatever
   task is needed to collect the information needed for the interrupt response.
5. The developer resumes generation by passing an interrupt response to the
   model. This action triggers a return to Step 2.

## Define manual-response interrupts

The most common kind of interrupt allows the LLM to request clarification from
the user, for example by asking a multiple-choice question.

For this use case, use the Genkit instance's `defineInterrupt()` method:

```ts
import { genkit, z } from 'genkit';
import { googleAI } from '@genkit-ai/google-genai';

const ai = genkit({
  plugins: [googleAI()],
  model: googleAI.model('gemini-2.5-flash'),
});

const askQuestion = ai.defineInterrupt({
  name: 'askQuestion',
  description: 'use this to ask the user a clarifying question',
  inputSchema: z.object({
    choices: z.array(z.string()).describe('the choices to display to the user'),
    allowOther: z.boolean().optional().describe('when true, allow write-ins'),
  }),
  outputSchema: z.string(),
});
```

Note that the `outputSchema` of an interrupt corresponds to the response data
you will provide as opposed to something that will be automatically populated
by a tool function.

### Use interrupts

Interrupts are passed into the `tools` array when generating content, just like
other types of tools. You can pass both normal tools and interrupts to the
same `generate` call:

<Tabs>
  <TabItem label="Generate">
    ```ts
    const response = await ai.generate({
      prompt: "Ask me a movie trivia question.",
      tools: [askQuestion],
    });
    ```
  </TabItem>
  <TabItem label="definePrompt">
    ```ts
    const triviaPrompt = ai.definePrompt({
      name: "triviaPrompt",
      tools: [askQuestion],
      input: {
        schema: z.object({ subject: z.string() }),
      },
      prompt: "Ask me a trivia question about {{subject}}.",
    });

    const response = await triviaPrompt({ subject: "computer history" });
    ```

  </TabItem>
  <TabItem label="Prompt file">
    ```dotprompt
    ---
    tools: [askQuestion]
    input:
      schema:
        partyType: string
    ---

    {{role "system"}}
    Use the askQuestion tool if you need to clarify something.

    {{role "user"}}
    Help me plan a
    {{partyType}}
    party next week.
    ```

    Then you can execute the prompt in your code as follows:

    ```ts
    // assuming prompt file is named partyPlanner.prompt
    const partyPlanner = ai.prompt("partyPlanner");

    const response = await partyPlanner({ partyType: "birthday" });
    ```

  </TabItem>
  <TabItem label="Chat">
    ```ts
    const chat = ai.chat({
      system: "Use the askQuestion tool if you need to clarify something.",
      tools: [askQuestion],
    });

    const response = await chat.send("make a plan for my birthday party");
    ```

  </TabItem>
</Tabs>

Genkit immediately returns a response on receipt of an interrupt tool call.

### Respond to interrupts

If you've passed one or more interrupts to your generate call, you
need to check the response for interrupts so that you can handle them:

```ts
// you can check the 'finishReason' of the response
response.finishReason === 'interrupted';
// or you can check to see if any interrupt requests are on the response
response.interrupts.length > 0;
```

Responding to an interrupt is done using the `resume` option on a subsequent
`generate` call, making sure to pass in the existing history. Each tool has
a `.respond()` method on it to help construct the response.

Once resumed, the model re-enters the generation loop, including tool
execution, until either it completes or another interrupt is triggered:

```ts
let response = await ai.generate({
  tools: [askQuestion],
  system: 'ask clarifying questions until you have a complete solution',
  prompt: 'help me plan a backyard BBQ',
});

while (response.interrupts.length) {
  const answers = [];
  // multiple interrupts can be called at once, so we handle them all
  for (const question of response.interrupts) {
    answers.push(
      // use the `respond` method on our tool to populate answers
      askQuestion.respond(
        question,
        // send the tool request input to the user to respond
        await askUser(question.toolRequest.input),
      ),
    );
  }

  response = await ai.generate({
    tools: [askQuestion],
    messages: response.messages,
    resume: {
      respond: answers,
    },
  });
}

// no more interrupts, we can see the final response
console.log(response.text);
```

## Tools with restartable interrupts

Another common pattern for interrupts is the need to _confirm_ an action that
the LLM suggests before actually performing it. For example, a payments app
might want the user to confirm certain kinds of transfers.

For this use case, you can use the standard `defineTool` method to add custom
logic around when to trigger an interrupt, and what to do when an interrupt is
_restarted_ with additional metadata.

### Define a restartable tool

Every tool has access to two special helpers in the second argument of its
implementation definition:

- `interrupt`: when called, this method throws a special kind of exception that
  is caught to pause the generation loop. You can provide additional metadata
  as an object.
- `resumed`: when a request from an interrupted generation is restarted using
  the `{resume: {restart: ...}}` option (see below), this helper contains the
  metadata provided when restarting.

If you were building a payments app, for example, you might want to confirm with
the user before making a transfer exceeding a certain amount:

```ts
const transferMoney = ai.defineTool(
  {
    name: 'transferMoney',
    description: 'Transfers money between accounts.',
    inputSchema: z.object({
      toAccountId: z.string().describe('the account id of the transfer destination'),
      amount: z.number().describe('the amount in integer cents (100 = $1.00)'),
    }),
    outputSchema: z.object({
      status: z.string().describe('the outcome of the transfer'),
      message: z.string().optional(),
    }),
  },
  async (input, { context, interrupt, resumed }) => {
    // if the user rejected the transaction
    if (resumed?.status === 'REJECTED') {
      return { status: 'REJECTED', message: 'The user rejected the transaction.' };
    }
    // trigger an interrupt to confirm if amount > $100
    if (resumed?.status !== 'APPROVED' && input.amount > 10000) {
      interrupt({
        message: 'Please confirm sending an amount > $100.',
      });
    }
    // complete the transaction if not interrupted
    return doTransfer(input);
  },
);
```

In this example, on first execution (when `resumed` is undefined), the tool
checks to see if the amount exceeds $100, and triggers an interrupt if so. On
second execution, it looks for a status in the new metadata provided and
performs the transfer or returns a rejection response, depending on whether it
is approved or rejected.

### Restart tools after interruption

Interrupt tools give you full control over:

1. When an initial tool request should trigger an interrupt.
2. When and whether to resume the generation loop.
3. What additional information to provide to the tool when resuming.

In the example shown in the previous section, the application might ask the user
to confirm the interrupted request to make sure the transfer amount is okay:

```ts
let response = await ai.generate({
  tools: [transferMoney],
  prompt: 'Transfer $1000 to account ABC123',
});

while (response.interrupts.length) {
  const confirmations = [];
  // multiple interrupts can be called at once, so we handle them all
  for (const interrupt of response.interrupts) {
    confirmations.push(
      // use the 'restart' method on our tool to provide `resumed` metadata
      transferMoney.restart(
        interrupt,
        // send the tool request input to the user to respond. assume that this
        // returns `{status: "APPROVED"}` or `{status: "REJECTED"}`
        await requestConfirmation(interrupt.toolRequest.input),
      ),
    );
  }

  response = await ai.generate({
    tools: [transferMoney],
    messages: response.messages,
    resume: {
      restart: confirmations,
    },
  });
}

// no more interrupts, we can see the final response
console.log(response.text);
```

</LanguageContent>
