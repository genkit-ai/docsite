---
title: Google AI plugin
description: Learn how to use Google's Gemini models with Genkit across JavaScript, Go, and Python, including text generation, embeddings, TTS, video generation, and context caching.
---

import LanguageSelector from '../../../../components/LanguageSelector.astro';
import CopyMarkdownButton from '../../../../components/CopyMarkdownButton.astro';
import LanguageContent from '../../../../components/LanguageContent.astro';

<div style="display: flex; justify-content: space-between; align-items: center; gap: 1rem; margin: 1rem 0 1rem 0;">
  <LanguageSelector />
  <CopyMarkdownButton />
</div>

The Google AI plugin provides interfaces to Google's Gemini models through the [Gemini API](https://ai.google.dev/docs/gemini_api_overview), offering powerful text generation, embeddings, text-to-speech, video generation, and context caching capabilities.

## Installation and Setup

<LanguageContent lang="js">
Install the Google AI plugin:

    ```bash
    npm install @genkit-ai/googleai
    ```

    Configure the plugin when initializing Genkit:

    ```ts
    import { genkit } from 'genkit';
    import { googleAI } from '@genkit-ai/googleai';

    const ai = genkit({
      plugins: [googleAI()],
    });
    ```
</LanguageContent>

<LanguageContent lang="go">
The Google AI plugin is included with the Genkit Go package:

    ```go
    import (
        "github.com/firebase/genkit/go/genkit"
        "github.com/firebase/genkit/go/plugins/googlegenai"
    )

    func main() {
        ctx := context.Background()
        g, err := genkit.Init(ctx,
            genkit.WithPlugins(&googlegenai.GoogleAI{}),
        )
        if err != nil {
            log.Fatal(err)
        }
    }
    ```
</LanguageContent>

<LanguageContent lang="python">
Install the Google AI plugin:

    ```bash
    pip install genkit-plugin-google-genai
    ```

    Configure the plugin when initializing Genkit:

    ```python
    from genkit.ai import Genkit
    from genkit.plugins.google_genai import GoogleGenai

    ai = Genkit(
        plugins=[GoogleGenai()],
    )
    ```
</LanguageContent>

## API Key Configuration

The plugin requires an API key for the Gemini API, which you can get from [Google AI Studio](https://aistudio.google.com/app/apikey).

<LanguageContent lang="js">
Configure your API key by doing one of the following:

    - Set the `GEMINI_API_KEY` environment variable:
      ```bash
      export GEMINI_API_KEY=your_api_key_here
      ```

    - Specify the API key when initializing the plugin:
      ```ts
      googleAI({ apiKey: yourKey });
      ```

    :::caution
    Don't embed your API key directly in code! Use environment variables or a service like Cloud Secret Manager.
    :::
</LanguageContent>

<LanguageContent lang="go">
Set the `GEMINI_API_KEY` environment variable:

    ```bash
    export GEMINI_API_KEY=your_api_key_here
    ```

    The plugin will automatically use this environment variable.
</LanguageContent>

<LanguageContent lang="python">
Set the `GEMINI_API_KEY` environment variable:

    ```bash
    export GEMINI_API_KEY=your_api_key_here
    ```

    The plugin will automatically use this environment variable.
</LanguageContent>

## Basic Usage

<LanguageContent lang="js">
Use the helper functions to reference models and embedders:

    ```ts
    import { googleAI } from '@genkit-ai/googleai';

    // Referencing models
    const model = googleAI.model('gemini-2.5-flash');
    const modelPro = googleAI.model('gemini-2.5-flash-lite');

    // Referencing embedders
    const embedder = googleAI.embedder('gemini-embedding-001');

    // Set default model
    const ai = genkit({
      plugins: [googleAI()],
      model: googleAI.model('gemini-2.5-flash'),
    });

    // Generate content
    const llmResponse = await ai.generate('Tell me a joke.');

    // Generate embeddings
    const embeddings = await ai.embed({
      embedder: googleAI.embedder('gemini-embedding-001'),
      content: 'Hello world',
    });
    ```
</LanguageContent>

<LanguageContent lang="go">
Use the models directly with the generation API:

    ```go
    import (
        "context"
        "github.com/firebase/genkit/go/ai"
        "github.com/firebase/genkit/go/genkit"
        "github.com/firebase/genkit/go/plugins/googlegenai"
    )

    func main() {
        ctx := context.Background()
        g, err := genkit.Init(ctx,
            genkit.WithPlugins(&googlegenai.GoogleAI{}),
            genkit.WithDefaultModel("googleai/gemini-2.5-flash"),
        )
        if err != nil {
            log.Fatal(err)
        }

        // Generate content
        resp, err := genkit.Generate(ctx, g,
            ai.WithPrompt("Tell me a joke."),
        )
        if err != nil {
            log.Fatal(err)
        }

        fmt.Println(resp.Text())
    }
    ```
</LanguageContent>

<LanguageContent lang="python">
Use the models with the generation API:

    ```python
    from genkit.ai import Genkit
    from genkit.plugins.google_genai import GoogleGenai, google_genai_name

    ai = Genkit(
        plugins=[GoogleGenai()],
        model=google_genai_name('gemini-2.5-flash'),
    )

    # Generate content
    response = await ai.generate('Tell me a joke.')
    print(response.text)

    # Generate embeddings
    embeddings = await ai.embed(
        embedder=google_genai_name('gemini-embedding-001'),
        content='Hello world',
    )
    ```
</LanguageContent>

## Working with Files

<LanguageContent lang="js">
You can use files uploaded to the Gemini Files API:

    ```ts
    import { GoogleAIFileManager } from '@google/generative-ai/server';

    const fileManager = new GoogleAIFileManager(process.env.GEMINI_API_KEY);
    const uploadResult = await fileManager.uploadFile('path/to/file.jpg', {
      mimeType: 'image/jpeg',
      displayName: 'Your Image',
    });

    const response = await ai.generate({
      model: googleAI.model('gemini-2.5-flash'),
      prompt: [
        { text: 'Describe this image:' },
        {
          media: {
            contentType: uploadResult.file.mimeType,
            url: uploadResult.file.uri,
          },
        },
      ],
    });
    ```
</LanguageContent>

<LanguageContent lang="go">
File handling in Go requires using the Google AI SDK directly for file uploads, then referencing the files in Genkit:

    ```go
    // Upload files using the Google AI SDK, then reference in Genkit
    // File upload implementation depends on your specific use case
    
    resp, err := genkit.Generate(ctx, g,
        ai.WithPrompt("Describe this image:"),
        ai.WithMedia(&ai.Media{
            ContentType: "image/jpeg",
            URL:         "uploaded_file_uri",
        }),
    )
    ```
</LanguageContent>

<LanguageContent lang="python">
File handling in Python requires using the Google AI SDK for uploads:

    ```python
    # Upload files using the Google AI SDK, then reference in Genkit
    # File upload implementation depends on your specific use case
    
    response = await ai.generate(
        prompt=[
            {'text': 'Describe this image:'},
            {
                'media': {
                    'contentType': 'image/jpeg',
                    'url': 'uploaded_file_uri',
                }
            }
        ],
        model=google_genai_name('gemini-2.5-flash'),
    )
    ```
</LanguageContent>

## Fine-tuned Models

<LanguageContent lang="js">
You can use models fine-tuned with the Google Gemini API. Follow the instructions from the [Gemini API](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?lang=python) or fine-tune using [AI Studio](https://aistudio.corp.google.com/app/tune).

    When calling a tuned model, use the tuned model's ID directly:

    ```ts
    const llmResponse = await ai.generate({
      prompt: 'Suggest an item for the menu of fish themed restaurant',
      model: googleAI.model('tunedModels/my-example-model-apbm8oqbvuv2'),
    });
    ```
</LanguageContent>

<LanguageContent lang="go">
Use fine-tuned models by specifying the tuned model ID:

    ```go
    resp, err := genkit.Generate(ctx, g,
        ai.WithPrompt("Suggest an item for the menu of fish themed restaurant"),
        ai.WithModelName("googleai/tunedModels/my-example-model-apbm8oqbvuv2"),
    )
    ```
</LanguageContent>

<LanguageContent lang="python">
Use fine-tuned models by specifying the tuned model ID:

    ```python
    response = await ai.generate(
        prompt='Suggest an item for the menu of fish themed restaurant',
        model=google_genai_name('tunedModels/my-example-model-apbm8oqbvuv2'),
    )
    ```
</LanguageContent>

## Text-to-Speech (TTS)

<LanguageContent lang="js">
Generate audio using the Gemini TTS model:

    ```ts
    import { writeFile } from 'node:fs/promises';

    const { media } = await ai.generate({
      model: googleAI.model('gemini-2.5-flash-preview-tts'),
      config: {
        responseModalities: ['AUDIO'],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { voiceName: 'Algenib' },
          },
        },
      },
      prompt: 'Say that Genkit is an amazing Gen AI library',
    });

    if (media) {
      const audioBuffer = Buffer.from(
        media.url.substring(media.url.indexOf(',') + 1),
        'base64'
      );
      await writeFile('output.wav', audioBuffer);
    }
    ```

    ### Multi-speaker Audio

    Generate audio with multiple speakers:

    ```ts
    const response = await ai.generate({
      model: googleAI.model('gemini-2.5-flash-preview-tts'),
      config: {
        responseModalities: ['AUDIO'],
        speechConfig: {
          multiSpeakerVoiceConfig: {
            speakerVoiceConfigs: [
              {
                speaker: 'Speaker1',
                voiceConfig: {
                  prebuiltVoiceConfig: { voiceName: 'Algenib' },
                },
              },
              {
                speaker: 'Speaker2',
                voiceConfig: {
                  prebuiltVoiceConfig: { voiceName: 'Achernar' },
                },
              },
            ],
          },
        },
      },
      prompt: `Here's the dialog:
        Speaker1: "Genkit is an amazing Gen AI library!"
        Speaker2: "I thought it was a framework."`,
    });
    ```
</LanguageContent>

<LanguageContent lang="go">
Text-to-speech functionality is currently available primarily in JavaScript. For Go applications, you would need to:

    1. Use the Google AI SDK directly for TTS functionality
    2. Or call a JavaScript-based service that handles TTS
    3. Or use Google Cloud Text-to-Speech API separately

    ```go
    // TTS is not directly supported in Go Genkit
    // Consider using Google Cloud Text-to-Speech API or
    // a JavaScript service for TTS functionality
    ```
</LanguageContent>

<LanguageContent lang="python">
Text-to-speech functionality is currently available primarily in JavaScript. For Python applications, you would need to:

    1. Use the Google AI SDK directly for TTS functionality
    2. Or call a JavaScript-based service that handles TTS
    3. Or use Google Cloud Text-to-Speech API separately

    ```python
    # TTS is not directly supported in Python Genkit
    # Consider using Google Cloud Text-to-Speech API or
    # a JavaScript service for TTS functionality
    ```
</LanguageContent>

## Video Generation (Veo)

<LanguageContent lang="js">
Generate videos using the Veo models:

    ```ts
    const videoFlow = ai.defineFlow('text-to-video-veo', async () => {
      let { operation } = await ai.generate({
        model: googleAI.model('veo-2.0-generate-001'),
        prompt: 'A majestic dragon soaring over a mystical forest at dawn.',
        config: {
          durationSeconds: 5,
          aspectRatio: '16:9',
        },
      });

      if (!operation) {
        throw new Error('Expected the model to return an operation');
      }

      // Wait until the operation completes
      while (!operation.done) {
        operation = await ai.checkOperation(operation);
        await new Promise((resolve) => setTimeout(resolve, 5000));
      }

      if (operation.error) {
        throw new Error('Failed to generate video: ' + operation.error.message);
      }

      const video = operation.output?.message?.content.find((p) => !!p.media);
      if (!video) {
        throw new Error('Failed to find the generated video');
      }

      return video;
    });
    ```

    ### Video from Photo Reference

    ```ts
    const startingImage = fs.readFileSync('photo.jpg', { encoding: 'base64' });

    let { operation } = await ai.generate({
      model: googleAI.model('veo-2.0-generate-001'),
      prompt: [
        { text: 'make the subject in the photo move' },
        {
          media: {
            contentType: 'image/jpeg',
            url: `data:image/jpeg;base64,${startingImage}`,
          },
        },
      ],
      config: {
        durationSeconds: 5,
        aspectRatio: '9:16',
        personGeneration: 'allow_adult',
      },
    });
    ```
</LanguageContent>

<LanguageContent lang="go">
Video generation functionality is currently available primarily in JavaScript. For Go applications, you would need to:

    1. Use the Google AI SDK directly for video generation
    2. Or call a JavaScript-based service that handles video generation
    3. Or implement video generation using the Gemini API directly

    ```go
    // Video generation is not directly supported in Go Genkit
    // Consider using the Google AI SDK directly or
    // a JavaScript service for video generation functionality
    ```
</LanguageContent>

<LanguageContent lang="python">
Video generation functionality is currently available primarily in JavaScript. For Python applications, you would need to:

    1. Use the Google AI SDK directly for video generation
    2. Or call a JavaScript-based service that handles video generation
    3. Or implement video generation using the Gemini API directly

    ```python
    # Video generation is not directly supported in Python Genkit
    # Consider using the Google AI SDK directly or
    # a JavaScript service for video generation functionality
    ```
</LanguageContent>

## Context Caching

<LanguageContent lang="js">
Context caching allows models to reuse previously cached content to optimize performance:

    ```ts
    const llmResponse = await ai.generate({
      messages: [
        {
          role: 'user',
          content: [{ text: 'Here is the relevant text from War and Peace.' }],
        },
        {
          role: 'model',
          content: [
            {
              text: 'Based on War and Peace, here is some analysis of Pierre Bezukhov\'s character.',
            },
          ],
          metadata: {
            cache: {
              ttlSeconds: 300, // Cache this message for 5 minutes
            },
          },
        },
      ],
      model: googleAI.model('gemini-2.5-flash-001'),
      prompt: 'Describe Pierre\'s transformation throughout the novel',
    });
    ```

    ### Caching Large Documents

    ```ts
    const textContent = await fs.readFile('path/to/war_and_peace.txt', 'utf-8');

    const llmResponse = await ai.generate({
      messages: [
        {
          role: 'user',
          content: [{ text: textContent }],
        },
        {
          role: 'model',
          content: [
            {
              text: 'This analysis is based on the provided text from War and Peace.',
            },
          ],
          metadata: {
            cache: {
              ttlSeconds: 300,
            },
          },
        },
      ],
      model: googleAI.model('gemini-2.5-flash-001'),
      prompt: 'Analyze the relationship between Pierre and Natasha.',
    });
    ```
</LanguageContent>

<LanguageContent lang="go">
Context caching functionality is currently available primarily in JavaScript. For Go applications, you would need to implement caching manually or use the Google AI SDK directly.

    ```go
    // Context caching is not directly supported in Go Genkit
    // Consider implementing your own caching layer or
    // using the Google AI SDK directly for caching functionality
    ```
</LanguageContent>

<LanguageContent lang="python">
Context caching functionality is currently available primarily in JavaScript. For Python applications, you would need to implement caching manually or use the Google AI SDK directly.

    ```python
    # Context caching is not directly supported in Python Genkit
    # Consider implementing your own caching layer or
    # using the Google AI SDK directly for caching functionality
    ```
</LanguageContent>

## Available Models

The Google AI plugin supports various Gemini models:

- **Text Generation**: `gemini-2.5-flash`, `gemini-2.5-flash-lite`, `gemini-1.5-pro`
- **Embeddings**: `gemini-embedding-001`
- **Text-to-Speech**: `gemini-2.5-flash-preview-tts`
- **Video Generation**: `veo-2.0-generate-001`, `veo-3.0-generate-preview`

## Next Steps

- Learn about [generating content](/docs/models) to understand how to use these models effectively
- Explore [tool calling](/docs/tool-calling) to add interactive capabilities to your AI applications
- See [creating flows](/docs/flows) to build structured AI workflows
- Check out [context](/docs/context) for managing information flow in your applications
