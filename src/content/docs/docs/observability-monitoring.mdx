---
title: Observability and Monitoring
description: Learn how to monitor and observe your Genkit AI workflows across JavaScript, Go, and Python, including local development tools, production monitoring, and OpenTelemetry integration.
---

import LanguageSelector from '../../../components/LanguageSelector.astro';
import CopyMarkdownButton from '../../../components/CopyMarkdownButton.astro';
import LanguageContent from '../../../components/LanguageContent.astro';

<div style="display: flex; justify-content: space-between; align-items: center; gap: 1rem; margin: 1rem 0 1rem 0;">
  <LanguageSelector />
  <CopyMarkdownButton />
</div>

Genkit provides comprehensive observability features to help you understand, debug, and optimize your AI workflows. Whether you're developing locally or running in production, Genkit offers the tools you need to monitor performance, trace execution, and troubleshoot issues.

## Overview

Genkit's observability stack includes:

- **Local Development Tools**: Built-in tracing and debugging via the Developer UI
- **Production Monitoring**: Firebase Genkit Monitoring dashboard for deployed applications
- **OpenTelemetry Integration**: Export telemetry data to any observability platform
- **Centralized Logging**: Structured logging with automatic export capabilities
- **Metrics Collection**: Performance metrics, error rates, and usage statistics

## Local Development Observability

### Developer UI Tracing

During development, Genkit automatically collects traces and provides detailed debugging capabilities through the Developer UI:

<LanguageContent lang="js">
The Developer UI is automatically available when you run:

    ```bash
    npx genkit start
    ```

    Features include:
    - **Step-by-step trace inspection**: See every step of your flow execution
    - **Input/output logging**: Examine data flowing through each step
    - **Performance metrics**: View latency and execution statistics
    - **Error debugging**: Detailed error information and stack traces
    - **Flow testing**: Run and test flows directly from the UI

</LanguageContent>

<LanguageContent lang="go">
The trace store feature is enabled automatically in development environments:

    ```bash
    genkit start
    # or
    genkit flow:run
    ```

    The Developer UI provides:
    - **Flow execution traces**: Complete visibility into flow steps
    - **Input/output inspection**: Debug data transformations
    - **Performance analysis**: Identify bottlenecks and optimization opportunities
    - **Interactive testing**: Test flows with different inputs

</LanguageContent>

<LanguageContent lang="python">
Development observability is built into the Genkit runtime:

    ```bash
    # Development server with tracing
    python -m genkit start
    ```

    Available features:
    - **Automatic trace collection**: No configuration required
    - **Real-time debugging**: Inspect flows as they execute
    - **Data flow visualization**: See how data moves through your workflow
    - **Error analysis**: Detailed error reporting and debugging

</LanguageContent>

### Local Logging

Genkit provides a centralized logging system that integrates with the observability stack:

<LanguageContent lang="js">
```ts
    import { logger } from 'genkit/logging';

    // Configure log level
    logger.setLogLevel('debug');

    // Use in your flows
    export const myFlow = ai.defineFlow(
      { name: 'myFlow' },
      async (input) => {
        logger.info('Flow started', { input });

        try {
          const result = await processData(input);
          logger.info('Flow completed successfully', { result });
          return result;
        } catch (error) {
          logger.error('Flow failed', { error: error.message });
          throw error;
        }
      }
    );
    ```

</LanguageContent>

<LanguageContent lang="go">
```go
    import (
        "context"
        "log/slog"
        "github.com/firebase/genkit/go/genkit"
    )

    func myFlow(ctx context.Context, input string) (string, error) {
        slog.InfoContext(ctx, "Flow started", "input", input)

        result, err := processData(input)
        if err != nil {
            slog.ErrorContext(ctx, "Flow failed", "error", err)
            return "", err
        }

        slog.InfoContext(ctx, "Flow completed", "result", result)
        return result, nil
    }
    ```

</LanguageContent>

<LanguageContent lang="python">
```python
    import logging
    from genkit.ai import Genkit

    # Configure logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    ai = Genkit()

    @ai.flow()
    async def my_flow(input: str) -> str:
        logger.info(f"Flow started with input: {input}")

        try:
            result = await process_data(input)
            logger.info(f"Flow completed successfully: {result}")
            return result
        except Exception as error:
            logger.error(f"Flow failed: {error}")
            raise
    ```

</LanguageContent>

## Production Monitoring

### Firebase Genkit Monitoring

For production deployments, Genkit integrates with Firebase to provide comprehensive monitoring through the Genkit Monitoring dashboard.

#### Setup and Configuration

<LanguageContent lang="js">
**1. Install the Firebase plugin:**

    ```bash
    npm install @genkit-ai/firebase
    ```

    **2. Environment-based configuration:**

    ```bash
    export ENABLE_FIREBASE_MONITORING=true
    ```

    **3. Programmatic configuration:**

    ```ts
    import { enableFirebaseTelemetry } from '@genkit-ai/firebase';

    // Basic setup
    enableFirebaseTelemetry();

    // Advanced configuration
    enableFirebaseTelemetry({
      forceDevExport: false,
      metricExportIntervalMillis: 300_000, // 5 minutes
      disableLoggingInputAndOutput: false,
      disableMetrics: false,
      disableTraces: false,
    });
    ```

</LanguageContent>

<LanguageContent lang="go">
**1. Install the Google Cloud plugin:**

    ```bash
    go get github.com/firebase/genkit/go/plugins/googlecloud
    ```

    **2. Configure telemetry export:**

    ```go
    import (
        "github.com/firebase/genkit/go/plugins/googlecloud"
    )

    func main() {
        ctx := context.Background()

        g, err := genkit.Init(ctx,
            genkit.WithPlugins(&googlecloud.GoogleCloud{}),
        )
        if err != nil {
            log.Fatal(err)
        }

        // Telemetry is automatically configured
    }
    ```

</LanguageContent>

<LanguageContent lang="python">
**1. Install monitoring dependencies:**

    ```bash
    pip install genkit[monitoring]
    ```

    **2. Configure telemetry:**

    ```python
    from genkit.ai import Genkit
    from genkit.monitoring import enable_firebase_monitoring

    # Enable monitoring
    enable_firebase_monitoring()

    ai = Genkit()
    ```

</LanguageContent>

#### Required Google Cloud APIs

Enable these APIs in your Google Cloud project:

- [Cloud Logging API](https://console.cloud.google.com/apis/library/logging.googleapis.com)
- [Cloud Trace API](https://console.cloud.google.com/apis/library/cloudtrace.googleapis.com)
- [Cloud Monitoring API](https://console.cloud.google.com/apis/library/monitoring.googleapis.com)

#### IAM Permissions

Grant these roles to your service account:

- **Monitoring Metric Writer** (`roles/monitoring.metricWriter`)
- **Cloud Trace Agent** (`roles/cloudtrace.agent`)
- **Logs Writer** (`roles/logging.logWriter`)

### Monitoring Dashboard Features

The [Genkit Monitoring dashboard](https://console.firebase.google.com/project/_/genai_monitoring) provides:

- **Performance Metrics**: Latency, throughput, and error rates
- **Usage Analytics**: Token consumption, model usage, and cost tracking
- **Trace Inspection**: Detailed execution traces with input/output logging
- **Error Analysis**: Error patterns, failure rates, and debugging information
- **Custom Metrics**: Application-specific metrics and KPIs

## OpenTelemetry Integration

Genkit is fully instrumented with [OpenTelemetry](https://opentelemetry.io/), allowing you to export telemetry data to any compatible observability platform.

### Custom OpenTelemetry Configuration

<LanguageContent lang="js">
```ts
    import { NodeSDK } from '@opentelemetry/sdk-node';
    import { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';
    import { JaegerExporter } from '@opentelemetry/exporter-jaeger';

    // Custom OpenTelemetry setup
    const sdk = new NodeSDK({
      traceExporter: new JaegerExporter({
        endpoint: 'http://localhost:14268/api/traces',
      }),
      instrumentations: [getNodeAutoInstrumentations()],
    });

    sdk.start();

    // Your Genkit app
    import { genkit } from 'genkit';
    const ai = genkit({ /* config */ });
    ```

</LanguageContent>

<LanguageContent lang="go">
```go
    import (
        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/exporters/jaeger"
        "go.opentelemetry.io/otel/sdk/trace"
    )

    func setupTelemetry() {
        // Create Jaeger exporter
        exp, err := jaeger.New(jaeger.WithCollectorEndpoint(
            jaeger.WithEndpoint("http://localhost:14268/api/traces"),
        ))
        if err != nil {
            log.Fatal(err)
        }

        // Create trace provider
        tp := trace.NewTracerProvider(
            trace.WithBatcher(exp),
        )

        otel.SetTracerProvider(tp)
    }
    ```

</LanguageContent>

<LanguageContent lang="python">
```python
    from opentelemetry import trace
    from opentelemetry.exporter.jaeger.thrift import JaegerExporter
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import BatchSpanProcessor

    # Configure OpenTelemetry
    trace.set_tracer_provider(TracerProvider())
    tracer = trace.get_tracer(__name__)

    jaeger_exporter = JaegerExporter(
        agent_host_name="localhost",
        agent_port=6831,
    )

    span_processor = BatchSpanProcessor(jaeger_exporter)
    trace.get_tracer_provider().add_span_processor(span_processor)
    ```

</LanguageContent>

### Popular Observability Platforms

Genkit's OpenTelemetry integration works with:

- **Jaeger**: Distributed tracing
- **Zipkin**: Request tracing and timing data
- **Prometheus**: Metrics collection and alerting
- **Grafana**: Visualization and dashboards
- **Datadog**: Full-stack monitoring
- **New Relic**: Application performance monitoring
- **Honeycomb**: Observability for complex systems

## Advanced Configuration

### Sampling and Performance

Control telemetry collection to balance observability with performance:

<LanguageContent lang="js">
```ts
    import { enableFirebaseTelemetry } from '@genkit-ai/firebase';
    import { TraceIdRatioBasedSampler } from '@opentelemetry/sdk-trace-base';

    enableFirebaseTelemetry({
      // Sample 10% of traces
      sampler: new TraceIdRatioBasedSampler(0.1),

      // Reduce export frequency for high-volume apps
      metricExportIntervalMillis: 600_000, // 10 minutes

      // Disable input/output logging for sensitive data
      disableLoggingInputAndOutput: true,

      // Custom auto-instrumentation
      autoInstrumentationConfig: {
        '@opentelemetry/instrumentation-fs': { enabled: false },
        '@opentelemetry/instrumentation-dns': { enabled: false },
      },
    });
    ```

</LanguageContent>

<LanguageContent lang="go">
```go
    import (
        "go.opentelemetry.io/otel/sdk/trace"
    )

    func setupSampling() {
        // Sample 10% of traces
        sampler := trace.TraceIDRatioBased(0.1)

        tp := trace.NewTracerProvider(
            trace.WithSampler(sampler),
            // Other configuration...
        )

        otel.SetTracerProvider(tp)
    }
    ```

</LanguageContent>

<LanguageContent lang="python">
```python
    from opentelemetry.sdk.trace.sampling import TraceIdRatioBasedSampler

    # Configure sampling
    sampler = TraceIdRatioBasedSampler(0.1)  # 10% sampling

    trace_provider = TracerProvider(sampler=sampler)
    trace.set_tracer_provider(trace_provider)
    ```

</LanguageContent>

### Custom Metrics

Add application-specific metrics to your observability stack:

<LanguageContent lang="js">
```ts
    import { metrics } from '@opentelemetry/api';

    const meter = metrics.getMeter('my-genkit-app');
    const requestCounter = meter.createCounter('genkit_requests_total');
    const responseTime = meter.createHistogram('genkit_response_time');

    export const myFlow = ai.defineFlow(
      { name: 'myFlow' },
      async (input) => {
        const startTime = Date.now();
        requestCounter.add(1, { flow: 'myFlow' });

        try {
          const result = await processData(input);
          responseTime.record(Date.now() - startTime, {
            flow: 'myFlow',
            status: 'success'
          });
          return result;
        } catch (error) {
          responseTime.record(Date.now() - startTime, {
            flow: 'myFlow',
            status: 'error'
          });
          throw error;
        }
      }
    );
    ```

</LanguageContent>

<LanguageContent lang="go">
```go
    import (
        "go.opentelemetry.io/otel/metric"
    )

    func setupMetrics() {
        meter := otel.Meter("my-genkit-app")

        requestCounter, _ := meter.Int64Counter("genkit_requests_total")
        responseTime, _ := meter.Float64Histogram("genkit_response_time")

        // Use in your flows
        requestCounter.Add(ctx, 1, metric.WithAttributes(
            attribute.String("flow", "myFlow"),
        ))
    }
    ```

</LanguageContent>

<LanguageContent lang="python">
```python
    from opentelemetry import metrics

    meter = metrics.get_meter(__name__)
    request_counter = meter.create_counter("genkit_requests_total")
    response_time = meter.create_histogram("genkit_response_time")

    @ai.flow()
    async def my_flow(input: str) -> str:
        start_time = time.time()
        request_counter.add(1, {"flow": "my_flow"})

        try:
            result = await process_data(input)
            response_time.record(
                time.time() - start_time,
                {"flow": "my_flow", "status": "success"}
            )
            return result
        except Exception as error:
            response_time.record(
                time.time() - start_time,
                {"flow": "my_flow", "status": "error"}
            )
            raise
    ```

</LanguageContent>

## Troubleshooting

### Common Issues

**Metrics not appearing in dashboard:**

- Verify API permissions and service account roles
- Check that required Google Cloud APIs are enabled
- Ensure `metricExportIntervalMillis` isn't too high
- Confirm network connectivity to Google Cloud services

**High telemetry costs:**

- Implement sampling to reduce data volume
- Disable input/output logging for large payloads
- Increase export intervals for non-critical environments
- Use trace sampling for high-traffic applications

**Missing traces in production:**

- Verify OpenTelemetry configuration
- Check service account permissions
- Ensure trace export is enabled
- Validate network connectivity

### Performance Optimization

**Reduce telemetry overhead:**

- Use appropriate sampling rates
- Disable unnecessary auto-instrumentations
- Batch exports efficiently
- Monitor telemetry export performance

**Optimize for production:**

- Disable development-only features
- Use environment-specific configurations
- Implement circuit breakers for telemetry exports
- Monitor resource usage

## Best Practices

### Development

1. **Use the Developer UI**: Take advantage of built-in tracing during development
2. **Test monitoring setup**: Verify telemetry collection before deploying
3. **Monitor resource usage**: Ensure observability doesn't impact performance
4. **Implement health checks**: Monitor the health of your monitoring system

### Production

1. **Implement alerting**: Set up alerts for critical metrics and errors
2. **Use dashboards**: Create custom dashboards for your specific use cases
3. **Monitor costs**: Track telemetry costs and optimize as needed
4. **Regular reviews**: Regularly review and optimize your observability setup

### Security

1. **Protect sensitive data**: Disable input/output logging for sensitive information
2. **Secure credentials**: Use proper IAM roles and service accounts
3. **Network security**: Ensure secure connections to observability platforms
4. **Data retention**: Configure appropriate data retention policies

## Next Steps

- Set up [Firebase Genkit Monitoring](https://console.firebase.google.com/project/_/genai_monitoring) for your production applications
- Explore [OpenTelemetry documentation](https://opentelemetry.io/docs/) for advanced configurations
- Learn about [evaluation](/docs/evaluation) to complement your monitoring strategy
- Check out [deployment guides](/docs/deployment) for production-ready configurations
