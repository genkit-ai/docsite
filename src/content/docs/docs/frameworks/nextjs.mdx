---
title: Next.js Integration
description: Learn how to integrate Genkit with Next.js applications across JavaScript, Go, and Python, including API routes, client-side calls, streaming, and deployment strategies.
---

import LanguageSelector from '../../../../components/LanguageSelector.astro';
import CopyMarkdownButton from '../../../../components/CopyMarkdownButton.astro';
import LanguageContent from '../../../../components/LanguageContent.astro';

<div style="display: flex; justify-content: space-between; align-items: center; gap: 1rem; margin: 1rem 0 1rem 0;">
  <LanguageSelector supportedLanguages="js"/>
  <CopyMarkdownButton />
</div>

<LanguageContent lang="go">

:::note[Guide unavailable for Go]
Specific Next.js integration guidance is not yet available for Go. See the general [web client integration guidance](/docs/client) instead.
:::

</LanguageContent>

<LanguageContent lang="python">

:::note[Guide unavailable for Python]
Specific Next.js integration guidance is not yet available for Python. See the general [web client integration guidance](/docs/client) instead.
:::

</LanguageContent>

<LanguageContent lang="js">

import { Tabs, TabItem } from '@astrojs/starlight/components';

This page shows how you can use Genkit flows in your Next.js applications using the official Genkit Next.js plugin. For complete API reference documentation, see the [Genkit Next.js Plugin API Reference](https://js.api.genkit.dev/modules/_genkit-ai_next.html).

## Before you begin

You should be familiar with Genkit's concept of [flows](/docs/flows), and how to write them.

## Create a Next.js project

If you don't already have a Next.js project that you want to add generative AI features to, you can create one for the purpose of following along with this page:

```bash
npx create-next-app@latest --src-dir
```

The `--src-dir` flag creates a `src/` directory to keep your project organized by separating source code from configuration files.

## Install Genkit dependencies

Install the Genkit dependencies into your Next.js app:

1.  Install the core Genkit library and the Next.js plugin:

    ```bash
    npm install genkit @genkit-ai/next
    ```

2.  Install at least one model plugin.

<Tabs syncKey="model-provider">
<TabItem label="Gemini (Google AI)">

```bash
npm install @genkit-ai/google-genai
```

</TabItem>
<TabItem label="Gemini (Vertex AI)">

    ```bash
    npm install @genkit-ai/vertexai
    ```

         </TabItem>

    </Tabs>

3.  Install the Genkit CLI globally. The tsx tool is also recommended as a development dependency, as it makes testing your code more convenient. Both of these dependencies are optional, however.

    ```bash
    npm install -g genkit-cli
    npm install --save-dev tsx
    ```

## Define Genkit flows

Create a new directory in your Next.js project to contain your Genkit flows. Create `src/genkit/` and add your flow definitions there:

For example, create `src/genkit/menuSuggestionFlow.ts`:

<Tabs syncKey="model-provider">
  <TabItem label="Gemini (Google AI)">
    ```ts
    import { googleAI } from '@genkit-ai/google-genai';
    import { genkit, z } from 'genkit';

    const ai = genkit({
      plugins: [googleAI()],
    });

    export const menuSuggestionFlow = ai.defineFlow(
      {
        name: 'menuSuggestionFlow',
        inputSchema: z.object({ theme: z.string() }),
        outputSchema: z.object({ menuItem: z.string() }),
        streamSchema: z.string(),
      },
      async ({ theme }, { sendChunk }) => {
        const { stream, response } = ai.generateStream({
          model: googleAI.model('gemini-2.5-flash'),
          prompt: `Invent a menu item for a ${theme} themed restaurant.`,
        });

        for await (const chunk of stream) {
          sendChunk(chunk.text);
        }

        const { text } = await response;
        return { menuItem: text };
      }
    );
    ```

  </TabItem>
  <TabItem label="Gemini (Vertex AI)">
    ```ts
    import { vertexAI } from '@genkit-ai/vertexai';
    import { genkit, z } from 'genkit';

    const ai = genkit({
      plugins: [vertexAI()],
    });

    export const menuSuggestionFlow = ai.defineFlow(
      {
        name: 'menuSuggestionFlow',
        inputSchema: z.object({ theme: z.string() }),
        outputSchema: z.object({ menuItem: z.string() }),
        streamSchema: z.string(),
      },
      async ({ theme }, { sendChunk }) => {
        const { stream, response } = ai.generateStream({
          model: vertexAI.model('gemini-2.5-flash'),
          prompt: `Invent a menu item for a ${theme} themed restaurant.`,
        });

        for await (const chunk of stream) {
          sendChunk(chunk.text);
        }

        const { text } = await response;
        return { menuItem: text };
      }
    );
    ```

  </TabItem>
</Tabs>

## Create API routes

Now, create API routes that expose your flows using the Genkit Next.js plugin. For each flow, create a corresponding route file:

Create `src/app/api/menuSuggestion/route.ts`:

```ts
import { menuSuggestionFlow } from '@/genkit/menuSuggestionFlow';
import { appRoute } from '@genkit-ai/next';

export const POST = appRoute(menuSuggestionFlow);
```

## Durable Streaming (Beta)

You can enable durable streaming for your flows, which allows clients to reconnect to a stream and replay the content. This is useful for long-running operations or unreliable networks.

To enable durable streaming, pass a `streamManager` to `appRoute`. See the [Durable Streaming documentation](/docs/durable-streaming#nextjs) for configuration and usage details.

## Call your flows from the frontend

In your frontend code, you can now call your flows using the Genkit Next.js client:

```tsx
'use client';

import { useState } from 'react';
import { runFlow, streamFlow } from '@genkit-ai/next/client';
import { menuSuggestionFlow } from '@/genkit/menuSuggestionFlow';

export default function Home() {
  const [menuItem, setMenuItem] = useState<string>('');
  const [isLoading, setIsLoading] = useState(false);
  const [streamedText, setStreamedText] = useState<string>('');

  async function getMenuItem(formData: FormData) {
    const theme = formData.get('theme')?.toString() ?? '';
    setIsLoading(true);

    try {
      // Regular (non-streaming) approach
      const result = await runFlow<typeof menuSuggestionFlow>({
        url: '/api/menuSuggestion',
        input: { theme },
      });

      setMenuItem(result.menuItem);
    } catch (error) {
      console.error('Error generating menu item:', error);
    } finally {
      setIsLoading(false);
    }
  }

  async function streamMenuItem(formData: FormData) {
    const theme = formData.get('theme')?.toString() ?? '';
    setIsLoading(true);
    setStreamedText('');

    try {
      // Streaming approach
      const result = streamFlow<typeof menuSuggestionFlow>({
        url: '/api/menuSuggestion',
        input: { theme },
      });

      // Process the stream chunks as they arrive
      for await (const chunk of result.stream) {
        setStreamedText((prev) => prev + chunk);
      }

      // Get the final complete response
      const finalOutput = await result.output;
      setMenuItem(finalOutput.menuItem);
    } catch (error) {
      console.error('Error streaming menu item:', error);
    } finally {
      setIsLoading(false);
    }
  }

  return (
    <main>
      <form action={getMenuItem}>
        <label htmlFor="theme">Suggest a menu item for a restaurant with this theme: </label>
        <input type="text" name="theme" id="theme" />
        <br />
        <br />
        <button type="submit" disabled={isLoading}>
          Generate
        </button>
        <button
          type="button"
          disabled={isLoading}
          onClick={(e) => {
            e.preventDefault();
            const formData = new FormData(e.currentTarget.form!);
            streamMenuItem(formData);
          }}
        >
          Stream Generation
        </button>
      </form>
      <br />

      {streamedText && (
        <div>
          <h3>Streaming Output:</h3>
          <pre>{streamedText}</pre>
        </div>
      )}

      {menuItem && (
        <div>
          <h3>Final Output:</h3>
          <pre>{menuItem}</pre>
        </div>
      )}
    </main>
  );
}
```

## Authentication (Optional)

If you need to add authentication to your API routes, you can pass headers with your requests:

```tsx
const result = await runFlow<typeof menuSuggestionFlow>({
  url: '/api/menuSuggestion',
  headers: {
    Authorization: 'Bearer your-token-here',
  },
  input: { theme },
});
```

## Test your app locally

If you want to run your app locally, you need to make credentials for the model API service you chose available.

<Tabs syncKey="model-provider">
  <TabItem label="Gemini (Google AI)">
    1. [Generate an API key](https://aistudio.google.com/app/apikey) for the Gemini API using Google AI Studio.

    2. Set the `GEMINI_API_KEY` environment variable to your key:

       ```bash
       export GEMINI_API_KEY=<your API key>
       ```

  </TabItem>
  <TabItem label="Gemini (Vertex AI)">
    1. In the Cloud console, [Enable the Vertex AI API](https://console.cloud.google.com/apis/library/aiplatform.googleapis.com?project=_) for your project.

    2. Configure the [`gcloud`](https://cloud.google.com/sdk/gcloud) tool to set up application default credentials:

       ```bash
       gcloud config set project <your project ID>
       gcloud services enable aiplatform.googleapis.com
       ```

  </TabItem>
</Tabs>

Then, run your app locally as normal:

```bash
npm run dev
```

For Genkit development tools, you can still use:

```bash
genkit start -- npx tsx --watch src/genkit/menuSuggestionFlow.ts
```

## Deploy your app

When you deploy your app, you will need to make sure the credentials for any external services you use (such as your chosen model API service) are available to the deployed app. See the following pages for information specific to your chosen deployment platform:

- [Cloud Functions for Firebase](/docs/deployment/firebase)
- [Cloud Run](/docs/deployment/cloud-run)
- [Other Node.js platforms](/docs/deployment/any-platform)

</LanguageContent>
